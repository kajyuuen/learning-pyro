{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/pyro-ppl/pyro/blob/c7f77f882c54cb8fc6bf463833c85857109ebc82/examples/dmm/polyphonic_data_loader.py\n",
    "def reverse_sequences(mini_batch, seq_lengths):\n",
    "    reversed_mini_batch = torch.zeros_like(mini_batch)\n",
    "    for b in range(mini_batch.size(0)):\n",
    "        T = seq_lengths[b]\n",
    "        time_slice = torch.arange(T - 1, -1, -1, device=mini_batch.device)\n",
    "        reversed_sequence = torch.index_select(mini_batch[b, :, :], 0, time_slice)\n",
    "        reversed_mini_batch[b, 0:T, :] = reversed_sequence\n",
    "    return reversed_mini_batch\n",
    "\n",
    "def pad_and_reverse(rnn_output, seq_lengths):\n",
    "    rnn_output, _ = nn.utils.rnn.pad_packed_sequence(rnn_output, batch_first=True)\n",
    "    reversed_output = reverse_sequences(rnn_output, seq_lengths)\n",
    "    return reversed_output\n",
    "\n",
    "# this function returns a 0/1 mask that can be used to mask out a mini-batch\n",
    "# composed of sequences of length `seq_lengths`\n",
    "def get_mini_batch_mask(mini_batch, seq_lengths):\n",
    "    mask = torch.zeros(mini_batch.shape[0:2])\n",
    "    for b in range(mini_batch.shape[0]):\n",
    "        mask[b, 0:seq_lengths[b]] = torch.ones(seq_lengths[b])\n",
    "    return mask\n",
    "\n",
    "\n",
    "# this function prepares a mini-batch for training or evaluation.\n",
    "# it returns a mini-batch in forward temporal order (`mini_batch`) as\n",
    "# well as a mini-batch in reverse temporal order (`mini_batch_reversed`).\n",
    "# it also deals with the fact that packed sequences (which are what what we\n",
    "# feed to the PyTorch rnn) need to be sorted by sequence length.\n",
    "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):\n",
    "    # get the sequence lengths of the mini-batch\n",
    "    seq_lengths = seq_lengths[mini_batch_indices]\n",
    "    # sort the sequence lengths\n",
    "    _, sorted_seq_length_indices = torch.sort(seq_lengths)\n",
    "    sorted_seq_length_indices = sorted_seq_length_indices.flip(0)\n",
    "    sorted_seq_lengths = seq_lengths[sorted_seq_length_indices]\n",
    "    sorted_mini_batch_indices = mini_batch_indices[sorted_seq_length_indices]\n",
    "\n",
    "    # compute the length of the longest sequence in the mini-batch\n",
    "    T_max = torch.max(seq_lengths)\n",
    "    # this is the sorted mini-batch\n",
    "    mini_batch = sequences[sorted_mini_batch_indices, 0:T_max, :]\n",
    "    # this is the sorted mini-batch in reverse temporal order\n",
    "    mini_batch_reversed = reverse_sequences(mini_batch, sorted_seq_lengths)\n",
    "    # get mask for mini-batch\n",
    "    mini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)\n",
    "\n",
    "    # cuda() here because need to cuda() before packing\n",
    "    if cuda:\n",
    "        mini_batch = mini_batch.cuda()\n",
    "        mini_batch_mask = mini_batch_mask.cuda()\n",
    "        mini_batch_reversed = mini_batch_reversed.cuda()\n",
    "\n",
    "    # do sequence packing\n",
    "    mini_batch_reversed = nn.utils.rnn.pack_padded_sequence(mini_batch_reversed,\n",
    "                                                            sorted_seq_lengths,\n",
    "                                                            batch_first=True)\n",
    "\n",
    "    return mini_batch, mini_batch_reversed, mini_batch_mask, sorted_seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    # p(x_t | z_t)\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        self.linear_z_to_hidden1 = nn.Linear(z_dim, emission_dim)\n",
    "        self.linear_hidden1_to_hidden2 = nn.Linear(emission_dim, emission_dim)\n",
    "        self.linear_hidden2_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, z_i):\n",
    "        h1 = self.relu(self.linear_z_to_hidden1(z_i))\n",
    "        h2 = self.relu(self.linear_hidden1_to_hidden2(h1))\n",
    "        ps = self.sigmoid(self.linear_hidden2_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    #  p(z_t | z_{t-1})\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # Neural Netwark\n",
    "        ## Gate: g\n",
    "        self.linear_gate_z_to_g1 = nn.Linear(z_dim, transition_dim)\n",
    "        self.linear_gate_g1_to_g2 = nn.Linear(transition_dim, z_dim)\n",
    "        ## Hidden: h\n",
    "        self.linear_hidden_z_to_h1 = nn.Linear(z_dim, transition_dim)\n",
    "        self.linear_hidden_h1_to_h2 = nn.Linear(transition_dim, z_dim)\n",
    "        ## loc, scale\n",
    "        self.linear_scale_z_to_mean = nn.Linear(z_dim, z_dim)\n",
    "        self.linear_loc_h2_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        # Init params\n",
    "        self.linear_loc_h2_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.linear_loc_h2_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        \n",
    "        # Non-linearities functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, z_t_1):\n",
    "        # Gate functions\n",
    "        g1 = self.relu(self.linear_gate_z_to_g1(z_t_1))\n",
    "        g2 = self.relu(self.linear_gate_g1_to_g2(g1))\n",
    "        \n",
    "        # h(proposed mean) functions\n",
    "        h1 = self.relu(self.linear_hidden_z_to_h1(z_t_1))\n",
    "        h2 = self.linear_hidden_h1_to_h2(h1)\n",
    "        \n",
    "        # Loc, Scale\n",
    "        loc = (1 - g2) * self.linear_scale_z_to_mean(z_t_1) + g2 *h2\n",
    "        scale = self.softplus(self.linear_loc_h2_to_loc(self.relu(h2)))\n",
    "        \n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        # linear functions\n",
    "        self.linear_z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.linear_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.linear_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        \n",
    "        # non-linear functions\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        # NOTE: 1/2はどこからきた\n",
    "        h_combined = 1/2 * (self.tanh(self.linear_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        \n",
    "        # Loc, Scale\n",
    "        loc = self.linear_hidden_to_loc(h_combined)\n",
    "        scale = self.softplus(self.linear_hidden_to_scale(h_combined))\n",
    "        \n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    def __init__(self,\n",
    "                           input_dim = 88,\n",
    "                           z_dim = 100,\n",
    "                           emission_dim = 100,\n",
    "                           transition_dim = 200,\n",
    "                           rnn_dim=600,\n",
    "                           rnn_dropout_rate=0.0,\n",
    "                           num_iafs=0,\n",
    "                           iaf_dim=50,\n",
    "                          use_cuda=False):\n",
    "        super().__init__()\n",
    "        # Model\n",
    "        ## Modules\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "\n",
    "        ## Init params\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "\n",
    "        # Guide\n",
    "        ## Modules\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        self.rnn = nn.RNN(input_size=input_dim, \n",
    "                                       hidden_size=rnn_dim,\n",
    "                                       nonlinearity='relu',\n",
    "                                       batch_first=True,\n",
    "                                       bidirectional=False,\n",
    "                                       num_layers=1,\n",
    "                                       dropout=rnn_dropout_rate)\n",
    "\n",
    "        ## Init params\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim)) # RNNの潜在変数\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        # if on gpu cuda-ize all pytorch (sub)modules\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, \n",
    "                       mini_batch, # (batch_size, seq_length, feature_size)\n",
    "                       mini_batch_reversed, \n",
    "                       mini_batch_mask, # (batch_size, seq_length)\n",
    "                       mini_batch_seq_lengths,\n",
    "                       annealing_factor=1.0):\n",
    "        \n",
    "        T_max = mini_batch.size(1)\n",
    "        \n",
    "        pyro.module(\"dmm\", self) # 自身のクラス(DMM)について記述\n",
    "\n",
    "        # z_prev に z_0を設定\n",
    "        z_prev = self.z_0.expand(mini_batch.size(0), self.z_0.size(0))\n",
    "\n",
    "        # 各データ系列から独立しているのでplateを使う\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch)):\n",
    "            # 潜在変数z_tと観測データxのサンプリングを行う\n",
    "            for t in range(1, T_max + 1):\n",
    "                # 多次元ガウス分布p(z_t | z_{t-1})のパラメータμとσを求める\n",
    "                z_loc, z_scale = self.trans(z_prev)\n",
    "                    \n",
    "                #　z_t ~ Normal(z_t | z_{t-1})のサンプリングをパラメータを用いて行う\n",
    "                # TODO: これ見る　http://pyro.ai/examples/effect_handlers.html\n",
    "                with poutine.scale(None, annealing_factor):\n",
    "                    z_t = pyro.sample(\"z_%d\" % t,\n",
    "                                          dist.Normal(z_loc, z_scale)\n",
    "                                          .mask(mini_batch_mask[:, t - 1:t])\n",
    "                                          .to_event(1))\n",
    "\n",
    "                # ベルヌーイ分布p(x_t|z_t)のパラメータを求める\n",
    "                emission_probs_t = self.emitter(z_t)\n",
    " \n",
    "                # x_t ~ Bern(x_t|z_t)のサンプリングをパラメータを用いて行う\n",
    "                pyro.sample(\"obs_x_%d\" % t,\n",
    "                            dist.Bernoulli(emission_probs_t)\n",
    "                                .mask(mini_batch_mask[:, t - 1:t])\n",
    "                                .to_event(1),\n",
    "                            obs=mini_batch[:, t - 1, :])\n",
    "                \n",
    "                #  z_prevの更新\n",
    "                z_prev = z_t\n",
    "\n",
    "    def guide(self, \n",
    "                       mini_batch, # (batch_size, seq_length, feature_size)\n",
    "                       mini_batch_reversed, \n",
    "                       mini_batch_mask, # (batch_size, seq_length)\n",
    "                       mini_batch_seq_lengths,\n",
    "                       annealing_factor=1.0):\n",
    "        T_max = mini_batch.size(1)\n",
    "        \n",
    "        pyro.module(\"dmm\", self) # 自身のクラス(DMM)について記述\n",
    "\n",
    "        # h_0\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0),\n",
    "                                                              self.rnn.hidden_size).contiguous()\n",
    "\n",
    "        # RNNの出力\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        rnn_output = pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "\n",
    "        # z_prev に z_q_0を設定\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "\n",
    "        # 各データ系列から独立しているのでplateを使う\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch)):\n",
    "            # 潜在変数z_tと観測データxのサンプリングを行う\n",
    "            for t in range(1, T_max + 1):\n",
    "                # 多次元ガウス分布q(z_t | z_{t-1}, x_{t:T})の分布を求める\n",
    "                z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "                z_dist = dist.Normal(z_loc, z_scale)\n",
    "                    \n",
    "                #　z_t ~ q(z_t | z_{t-1}, x_{t:T})\n",
    "                with pyro.poutine.scale(None, annealing_factor):\n",
    "                    z_t = pyro.sample(\"z_%d\" % t,\n",
    "                                                      z_dist.mask(mini_batch_mask[:, t - 1:t])\n",
    "                                                     .to_event(1))                \n",
    "                #  z_prevの更新\n",
    "                z_prev = z_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "dmm = DMM(use_cuda=device)\n",
    "\n",
    "adam_params = {\n",
    "    \"lr\": 0.01, \n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"clip_norm\": 0,\n",
    "    \"lrd\": 0,\n",
    "    \"weight_decay\": 0\n",
    "}\n",
    "\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "svi = SVI(dmm.model, dmm.guide, optimizer, Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Observations in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (0.1.4)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (from Observations) (1.18.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (from Observations) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os.path import exists, join\n",
    "from observations import jsb_chorales\n",
    "\n",
    "def process_data(base_path, filename, T_max=160, min_note=21, note_range=88):\n",
    "    output = join(base_path, filename)\n",
    "    if exists(output):\n",
    "        return\n",
    "\n",
    "    print(\"processing raw polyphonic music data...\")\n",
    "    data = jsb_chorales(base_path)\n",
    "    processed_dataset = {}\n",
    "    for split, data_split in zip(['train', 'test', 'valid'], data):\n",
    "        processed_dataset[split] = {}\n",
    "        n_seqs = len(data_split)\n",
    "        processed_dataset[split]['sequence_lengths'] = np.zeros((n_seqs), dtype=np.int32)\n",
    "        processed_dataset[split]['sequences'] = np.zeros((n_seqs, T_max, note_range))\n",
    "        for seq in range(n_seqs):\n",
    "            seq_length = len(data_split[seq])\n",
    "            processed_dataset[split]['sequence_lengths'][seq] = seq_length\n",
    "            for t in range(seq_length):\n",
    "                note_slice = np.array(list(data_split[seq][t])) - min_note\n",
    "                slice_length = len(note_slice)\n",
    "                if slice_length > 0:\n",
    "                    processed_dataset[split]['sequences'][seq, t, note_slice] = np.ones((slice_length))\n",
    "    pickle.dump(processed_dataset, open(output, \"wb\"))\n",
    "    print(\"dumped processed data to %s\" % output)\n",
    "\n",
    "\n",
    "! pip install Observations\n",
    "base_path = '../data'\n",
    "process_data(base_path, \"jsb_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 20\n",
    "\n",
    "jsb_file_loc = \"../data/jsb_processed.pkl\"\n",
    "data = pickle.load(open(jsb_file_loc, \"rb\"))\n",
    "training_seq_lengths = torch.tensor(data['train']['sequence_lengths']).to(device)\n",
    "training_data_sequences = torch.tensor(data['train']['sequences']).float().to(device)\n",
    "test_seq_lengths = torch.tensor(data['test']['sequence_lengths']).to(device)\n",
    "test_data_sequences = torch.tensor(data['test']['sequences']).float().to(device)\n",
    "val_seq_lengths = torch.tensor(data['valid']['sequence_lengths']).to(device)\n",
    "val_data_sequences = torch.tensor(data['valid']['sequences']).float().to(device)\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = float(training_seq_lengths.sum())\n",
    "N_mini_batches = int(N_train_data / mini_batch_size +\n",
    "                     int(N_train_data % mini_batch_size > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minibatch(epoch,\n",
    "                                         which_mini_batch,\n",
    "                                         shuffled_indices,\n",
    "                                         annealing_epochs=1000,\n",
    "                                         minimum_annealing_factor=0.1,\n",
    "                                         mini_batch_size=20,\n",
    "                                         cuda=True):\n",
    "    if annealing_epochs > 0 and epoch < annealing_epochs:\n",
    "        # compute the KL annealing factor appropriate\n",
    "        # for the current mini-batch in the current epoch\n",
    "        min_af = minimum_annealing_factor\n",
    "        annealing_factor = min_af + (1.0 - min_af) * \\\n",
    "            (float(which_mini_batch + epoch * N_mini_batches + 1) /\n",
    "             float(annealing_epochs * N_mini_batches))\n",
    "    else:\n",
    "        # by default the KL annealing factor is unity\n",
    "        annealing_factor = 1.0\n",
    "\n",
    "    # compute which sequences in the training set we should grab\n",
    "    mini_batch_start = (which_mini_batch * mini_batch_size)\n",
    "    mini_batch_end = np.min([(which_mini_batch + 1) * mini_batch_size,\n",
    "                             N_train_data])\n",
    "    mini_batch_indices = torch.tensor(shuffled_indices[mini_batch_start:mini_batch_end]).to(cuda)\n",
    "    # grab the fully prepped mini-batch using the helper function in the data loader\n",
    "    mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "        = get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                              training_seq_lengths, cuda=cuda)\n",
    "    # do an actual gradient step\n",
    "    loss = svi.step(mini_batch, mini_batch_reversed, mini_batch_mask,\n",
    "                     mini_batch_seq_lengths, annealing_factor)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training epoch 0000]  63.5615 \t\t\t\t(dt = 6.292 sec)\n",
      "[training epoch 0001]  63.5628 \t\t\t\t(dt = 6.191 sec)\n",
      "[training epoch 0002]  63.5850 \t\t\t\t(dt = 6.298 sec)\n",
      "[training epoch 0003]  63.5946 \t\t\t\t(dt = 6.147 sec)\n",
      "[training epoch 0004]  63.5983 \t\t\t\t(dt = 6.162 sec)\n",
      "[training epoch 0005]  63.6200 \t\t\t\t(dt = 6.268 sec)\n",
      "[training epoch 0006]  63.6389 \t\t\t\t(dt = 6.807 sec)\n",
      "[training epoch 0007]  63.6525 \t\t\t\t(dt = 6.877 sec)\n",
      "[training epoch 0008]  63.6802 \t\t\t\t(dt = 6.773 sec)\n",
      "[training epoch 0009]  63.6724 \t\t\t\t(dt = 6.453 sec)\n",
      "[training epoch 0010]  63.6878 \t\t\t\t(dt = 6.497 sec)\n",
      "[training epoch 0011]  63.7204 \t\t\t\t(dt = 6.414 sec)\n",
      "[training epoch 0012]  63.7202 \t\t\t\t(dt = 6.247 sec)\n",
      "[training epoch 0013]  63.7429 \t\t\t\t(dt = 6.109 sec)\n",
      "[training epoch 0014]  63.7456 \t\t\t\t(dt = 6.228 sec)\n",
      "[training epoch 0015]  63.7693 \t\t\t\t(dt = 5.911 sec)\n",
      "[training epoch 0016]  63.7848 \t\t\t\t(dt = 5.275 sec)\n",
      "[training epoch 0017]  63.7971 \t\t\t\t(dt = 5.360 sec)\n",
      "[training epoch 0018]  63.8149 \t\t\t\t(dt = 5.550 sec)\n",
      "[training epoch 0019]  63.8303 \t\t\t\t(dt = 5.418 sec)\n",
      "[training epoch 0020]  63.8432 \t\t\t\t(dt = 5.559 sec)\n",
      "[training epoch 0021]  63.8537 \t\t\t\t(dt = 5.353 sec)\n",
      "[training epoch 0022]  63.8786 \t\t\t\t(dt = 5.363 sec)\n",
      "[training epoch 0023]  63.8845 \t\t\t\t(dt = 5.141 sec)\n",
      "[training epoch 0024]  63.8957 \t\t\t\t(dt = 5.029 sec)\n",
      "[training epoch 0025]  63.9090 \t\t\t\t(dt = 4.996 sec)\n",
      "[training epoch 0026]  63.9359 \t\t\t\t(dt = 5.300 sec)\n",
      "[training epoch 0027]  63.9427 \t\t\t\t(dt = 5.292 sec)\n",
      "[training epoch 0028]  63.9600 \t\t\t\t(dt = 5.475 sec)\n",
      "[training epoch 0029]  63.9698 \t\t\t\t(dt = 5.322 sec)\n",
      "[training epoch 0030]  64.0004 \t\t\t\t(dt = 5.176 sec)\n",
      "[training epoch 0031]  63.9906 \t\t\t\t(dt = 5.037 sec)\n",
      "[training epoch 0032]  64.0247 \t\t\t\t(dt = 5.126 sec)\n",
      "[training epoch 0033]  64.0168 \t\t\t\t(dt = 5.213 sec)\n",
      "[training epoch 0034]  64.0314 \t\t\t\t(dt = 5.087 sec)\n",
      "[training epoch 0035]  64.0656 \t\t\t\t(dt = 5.162 sec)\n",
      "[training epoch 0036]  64.0779 \t\t\t\t(dt = 5.471 sec)\n",
      "[training epoch 0037]  64.0991 \t\t\t\t(dt = 5.356 sec)\n",
      "[training epoch 0038]  64.1023 \t\t\t\t(dt = 5.344 sec)\n",
      "[training epoch 0039]  64.1336 \t\t\t\t(dt = 5.417 sec)\n",
      "[training epoch 0040]  64.1296 \t\t\t\t(dt = 5.260 sec)\n",
      "[training epoch 0041]  64.1492 \t\t\t\t(dt = 5.534 sec)\n",
      "[training epoch 0042]  64.1730 \t\t\t\t(dt = 5.544 sec)\n",
      "[training epoch 0043]  64.1864 \t\t\t\t(dt = 5.320 sec)\n",
      "[training epoch 0044]  64.1986 \t\t\t\t(dt = 5.207 sec)\n",
      "[training epoch 0045]  64.2054 \t\t\t\t(dt = 5.303 sec)\n",
      "[training epoch 0046]  64.2203 \t\t\t\t(dt = 5.177 sec)\n",
      "[training epoch 0047]  64.2326 \t\t\t\t(dt = 4.979 sec)\n",
      "[training epoch 0048]  64.2539 \t\t\t\t(dt = 5.459 sec)\n",
      "[training epoch 0049]  64.2868 \t\t\t\t(dt = 5.194 sec)\n",
      "[training epoch 0050]  64.2715 \t\t\t\t(dt = 5.101 sec)\n",
      "[training epoch 0051]  64.2928 \t\t\t\t(dt = 5.274 sec)\n",
      "[training epoch 0052]  64.3218 \t\t\t\t(dt = 5.229 sec)\n",
      "[training epoch 0053]  64.3376 \t\t\t\t(dt = 5.226 sec)\n",
      "[training epoch 0054]  64.3230 \t\t\t\t(dt = 5.325 sec)\n",
      "[training epoch 0055]  64.3621 \t\t\t\t(dt = 5.142 sec)\n",
      "[training epoch 0056]  64.3629 \t\t\t\t(dt = 5.162 sec)\n",
      "[training epoch 0057]  64.3836 \t\t\t\t(dt = 5.160 sec)\n",
      "[training epoch 0058]  64.3841 \t\t\t\t(dt = 5.446 sec)\n",
      "[training epoch 0059]  64.4169 \t\t\t\t(dt = 5.100 sec)\n",
      "[training epoch 0060]  64.4359 \t\t\t\t(dt = 5.351 sec)\n",
      "[training epoch 0061]  64.4341 \t\t\t\t(dt = 5.297 sec)\n",
      "[training epoch 0062]  64.4626 \t\t\t\t(dt = 5.154 sec)\n",
      "[training epoch 0063]  64.4831 \t\t\t\t(dt = 5.067 sec)\n",
      "[training epoch 0064]  64.4693 \t\t\t\t(dt = 5.450 sec)\n",
      "[training epoch 0065]  64.5132 \t\t\t\t(dt = 5.368 sec)\n",
      "[training epoch 0066]  64.5107 \t\t\t\t(dt = 5.303 sec)\n",
      "[training epoch 0067]  64.5253 \t\t\t\t(dt = 5.119 sec)\n",
      "[training epoch 0068]  64.5451 \t\t\t\t(dt = 5.375 sec)\n",
      "[training epoch 0069]  64.5578 \t\t\t\t(dt = 5.041 sec)\n",
      "[training epoch 0070]  64.5743 \t\t\t\t(dt = 5.343 sec)\n",
      "[training epoch 0071]  64.5840 \t\t\t\t(dt = 5.449 sec)\n",
      "[training epoch 0072]  64.6003 \t\t\t\t(dt = 5.073 sec)\n",
      "[training epoch 0073]  64.6093 \t\t\t\t(dt = 5.056 sec)\n",
      "[training epoch 0074]  64.6108 \t\t\t\t(dt = 5.147 sec)\n",
      "[training epoch 0075]  64.6505 \t\t\t\t(dt = 4.935 sec)\n",
      "[training epoch 0076]  64.6509 \t\t\t\t(dt = 5.170 sec)\n",
      "[training epoch 0077]  64.6702 \t\t\t\t(dt = 5.015 sec)\n",
      "[training epoch 0078]  64.6703 \t\t\t\t(dt = 5.177 sec)\n",
      "[training epoch 0079]  64.7192 \t\t\t\t(dt = 5.014 sec)\n",
      "[training epoch 0080]  64.7120 \t\t\t\t(dt = 4.943 sec)\n",
      "[training epoch 0081]  64.7466 \t\t\t\t(dt = 5.146 sec)\n",
      "[training epoch 0082]  64.7565 \t\t\t\t(dt = 5.258 sec)\n",
      "[training epoch 0083]  64.7650 \t\t\t\t(dt = 5.100 sec)\n",
      "[training epoch 0084]  64.7668 \t\t\t\t(dt = 5.148 sec)\n",
      "[training epoch 0085]  64.7760 \t\t\t\t(dt = 5.449 sec)\n",
      "[training epoch 0086]  64.7966 \t\t\t\t(dt = 5.495 sec)\n",
      "[training epoch 0087]  64.8137 \t\t\t\t(dt = 5.312 sec)\n",
      "[training epoch 0088]  64.8248 \t\t\t\t(dt = 5.380 sec)\n",
      "[training epoch 0089]  64.8439 \t\t\t\t(dt = 5.434 sec)\n",
      "[training epoch 0090]  64.8608 \t\t\t\t(dt = 5.246 sec)\n",
      "[training epoch 0091]  64.8628 \t\t\t\t(dt = 5.517 sec)\n",
      "[training epoch 0092]  64.8962 \t\t\t\t(dt = 5.062 sec)\n",
      "[training epoch 0093]  64.9055 \t\t\t\t(dt = 5.345 sec)\n",
      "[training epoch 0094]  64.9206 \t\t\t\t(dt = 5.286 sec)\n",
      "[training epoch 0095]  64.9371 \t\t\t\t(dt = 5.051 sec)\n",
      "[training epoch 0096]  64.9621 \t\t\t\t(dt = 5.022 sec)\n",
      "[training epoch 0097]  64.9682 \t\t\t\t(dt = 5.128 sec)\n",
      "[training epoch 0098]  64.9972 \t\t\t\t(dt = 5.379 sec)\n",
      "[training epoch 0099]  65.0080 \t\t\t\t(dt = 5.199 sec)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "times = [time.time()]\n",
    "for epoch in range(num_epochs):\n",
    "    # accumulator for our estimate of the negative log likelihood\n",
    "    # (or rather -elbo) for this epoch\n",
    "    epoch_nll = 0.0\n",
    "    # prepare mini-batch subsampling indices for this epoch\n",
    "    shuffled_indices = np.arange(N_train_data)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "\n",
    "    # process each mini-batch; this is where we take gradient steps\n",
    "    for which_mini_batch in range(N_mini_batches):\n",
    "        epoch_nll += process_minibatch(epoch, which_mini_batch, shuffled_indices, cuda=device)\n",
    "    \n",
    "    # report training diagnostics\n",
    "    times.append(time.time())\n",
    "    epoch_time = times[-1] - times[-2]\n",
    "    print(\"[training epoch %04d]  %.4f \\t\\t\\t\\t(dt = %.3f sec)\" %\n",
    "        (epoch, epoch_nll / N_train_time_slices, epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
