{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/pyro-ppl/pyro/blob/c7f77f882c54cb8fc6bf463833c85857109ebc82/examples/dmm/polyphonic_data_loader.py\n",
    "def reverse_sequences(mini_batch, seq_lengths):\n",
    "    reversed_mini_batch = torch.zeros_like(mini_batch)\n",
    "    for b in range(mini_batch.size(0)):\n",
    "        T = seq_lengths[b]\n",
    "        time_slice = torch.arange(T - 1, -1, -1, device=mini_batch.device)\n",
    "        reversed_sequence = torch.index_select(mini_batch[b, :, :], 0, time_slice)\n",
    "        reversed_mini_batch[b, 0:T, :] = reversed_sequence\n",
    "    return reversed_mini_batch\n",
    "\n",
    "def pad_and_reverse(rnn_output, seq_lengths):\n",
    "    rnn_output, _ = nn.utils.rnn.pad_packed_sequence(rnn_output, batch_first=True)\n",
    "    reversed_output = reverse_sequences(rnn_output, seq_lengths)\n",
    "    return reversed_output\n",
    "\n",
    "# this function returns a 0/1 mask that can be used to mask out a mini-batch\n",
    "# composed of sequences of length `seq_lengths`\n",
    "def get_mini_batch_mask(mini_batch, seq_lengths):\n",
    "    mask = torch.zeros(mini_batch.shape[0:2])\n",
    "    for b in range(mini_batch.shape[0]):\n",
    "        mask[b, 0:seq_lengths[b]] = torch.ones(seq_lengths[b])\n",
    "    return mask\n",
    "\n",
    "\n",
    "# this function prepares a mini-batch for training or evaluation.\n",
    "# it returns a mini-batch in forward temporal order (`mini_batch`) as\n",
    "# well as a mini-batch in reverse temporal order (`mini_batch_reversed`).\n",
    "# it also deals with the fact that packed sequences (which are what what we\n",
    "# feed to the PyTorch rnn) need to be sorted by sequence length.\n",
    "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):\n",
    "    # get the sequence lengths of the mini-batch\n",
    "    seq_lengths = seq_lengths[mini_batch_indices]\n",
    "    # sort the sequence lengths\n",
    "    _, sorted_seq_length_indices = torch.sort(seq_lengths)\n",
    "    sorted_seq_length_indices = sorted_seq_length_indices.flip(0)\n",
    "    sorted_seq_lengths = seq_lengths[sorted_seq_length_indices]\n",
    "    sorted_mini_batch_indices = mini_batch_indices[sorted_seq_length_indices]\n",
    "\n",
    "    # compute the length of the longest sequence in the mini-batch\n",
    "    T_max = torch.max(seq_lengths)\n",
    "    # this is the sorted mini-batch\n",
    "    mini_batch = sequences[sorted_mini_batch_indices, 0:T_max, :]\n",
    "    # this is the sorted mini-batch in reverse temporal order\n",
    "    mini_batch_reversed = reverse_sequences(mini_batch, sorted_seq_lengths)\n",
    "    # get mask for mini-batch\n",
    "    mini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)\n",
    "\n",
    "    # cuda() here because need to cuda() before packing\n",
    "    if cuda:\n",
    "        mini_batch = mini_batch.cuda()\n",
    "        mini_batch_mask = mini_batch_mask.cuda()\n",
    "        mini_batch_reversed = mini_batch_reversed.cuda()\n",
    "\n",
    "    # do sequence packing\n",
    "    mini_batch_reversed = nn.utils.rnn.pack_padded_sequence(mini_batch_reversed,\n",
    "                                                            sorted_seq_lengths,\n",
    "                                                            batch_first=True)\n",
    "\n",
    "    return mini_batch, mini_batch_reversed, mini_batch_mask, sorted_seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    # p(x_t | z_t)\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        self.linear_z_to_hidden1 = nn.Linear(z_dim, emission_dim)\n",
    "        self.linear_hidden1_to_hidden2 = nn.Linear(emission_dim, emission_dim)\n",
    "        self.linear_hidden2_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, z_i):\n",
    "        h1 = self.relu(self.linear_z_to_hidden1(z_i))\n",
    "        h2 = self.relu(self.linear_hidden1_to_hidden2(h1))\n",
    "        ps = self.sigmoid(self.linear_hidden2_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    #  p(z_t | z_{t-1})\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # Neural Netwark\n",
    "        ## Gate: g\n",
    "        self.linear_gate_z_to_g1 = nn.Linear(z_dim, transition_dim)\n",
    "        self.linear_gate_g1_to_g2 = nn.Linear(transition_dim, z_dim)\n",
    "        ## Hidden: h\n",
    "        self.linear_hidden_z_to_h1 = nn.Linear(z_dim, transition_dim)\n",
    "        self.linear_hidden_h1_to_h2 = nn.Linear(transition_dim, z_dim)\n",
    "        ## loc, scale\n",
    "        self.linear_scale_z_to_mean = nn.Linear(z_dim, z_dim)\n",
    "        self.linear_loc_h2_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        # Init params\n",
    "        self.linear_loc_h2_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.linear_loc_h2_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        \n",
    "        # Non-linearities functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, z_t_1):\n",
    "        # Gate functions\n",
    "        g1 = self.relu(self.linear_gate_z_to_g1(z_t_1))\n",
    "        g2 = self.relu(self.linear_gate_g1_to_g2(g1))\n",
    "        \n",
    "        # h(proposed mean) functions\n",
    "        h1 = self.relu(self.linear_hidden_z_to_h1(z_t_1))\n",
    "        h2 = self.linear_hidden_h1_to_h2(h1)\n",
    "        \n",
    "        # Loc, Scale\n",
    "        loc = (1 - g2) * self.linear_scale_z_to_mean(z_t_1) + g2 *h2\n",
    "        scale = self.softplus(self.linear_loc_h2_to_loc(self.relu(h2)))\n",
    "        \n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        # linear functions\n",
    "        self.linear_z_to_hidden = nn.Linear(z_dim, rnn_dim)\n",
    "        self.linear_hidden_to_loc = nn.Linear(rnn_dim, z_dim)\n",
    "        self.linear_hidden_to_scale = nn.Linear(rnn_dim, z_dim)\n",
    "        \n",
    "        # non-linear functions\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        # NOTE: 1/2はどこからきた\n",
    "        h_combined = 1/2 * (self.tanh(self.linear_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        \n",
    "        # Loc, Scale\n",
    "        loc = self.linear_hidden_to_loc(h_combined)\n",
    "        scale = self.softplus(self.linear_hidden_to_scale(h_combined))\n",
    "        \n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    def __init__(self,\n",
    "                           input_dim = 88,\n",
    "                           z_dim = 100,\n",
    "                           emission_dim = 100,\n",
    "                           transition_dim = 200,\n",
    "                           rnn_dim=600,\n",
    "                           rnn_dropout_rate=0.0,\n",
    "                           num_iafs=0,\n",
    "                           iaf_dim=50,\n",
    "                          use_cuda=False):\n",
    "        super().__init__()\n",
    "        # Model\n",
    "        ## Modules\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "\n",
    "        ## Init params\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "\n",
    "        # Guide\n",
    "        ## Modules\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        self.rnn = nn.RNN(input_size=input_dim, \n",
    "                                       hidden_size=rnn_dim,\n",
    "                                       nonlinearity='relu',\n",
    "                                       batch_first=True,\n",
    "                                       bidirectional=False,\n",
    "                                       num_layers=1,\n",
    "                                       dropout=rnn_dropout_rate)\n",
    "\n",
    "        ## Init params\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim)) # RNNの潜在変数\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        # if on gpu cuda-ize all pytorch (sub)modules\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, \n",
    "                       mini_batch, # (batch_size, seq_length, feature_size)\n",
    "                       mini_batch_reversed, \n",
    "                       mini_batch_mask, # (batch_size, seq_length)\n",
    "                       mini_batch_seq_lengths,\n",
    "                       annealing_factor=1.0):\n",
    "        \n",
    "        T_max = mini_batch.size(1)\n",
    "        \n",
    "        pyro.module(\"dmm\", self) # 自身のクラス(DMM)について記述\n",
    "\n",
    "        # z_prev に z_0を設定\n",
    "        z_prev = self.z_0.expand(mini_batch.size(0), self.z_0.size(0))\n",
    "\n",
    "        # 各データ系列から独立しているのでplateを使う\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch)):\n",
    "            # 潜在変数z_tと観測データxのサンプリングを行う\n",
    "            for t in range(1, T_max + 1):\n",
    "                # 多次元ガウス分布p(z_t | z_{t-1})のパラメータμとσを求める\n",
    "                z_loc, z_scale = self.trans(z_prev)\n",
    "                    \n",
    "                #　z_t ~ Normal(z_t | z_{t-1})のサンプリングをパラメータを用いて行う\n",
    "                # TODO: これ見る　http://pyro.ai/examples/effect_handlers.html\n",
    "                with poutine.scale(None, annealing_factor):\n",
    "                    z_t = pyro.sample(\"z_%d\" % t,\n",
    "                                          dist.Normal(z_loc, z_scale)\n",
    "                                          .mask(mini_batch_mask[:, t - 1:t])\n",
    "                                          .to_event(1))\n",
    "\n",
    "                # ベルヌーイ分布p(x_t|z_t)のパラメータを求める\n",
    "                emission_probs_t = self.emitter(z_t)\n",
    " \n",
    "                # x_t ~ Bern(x_t|z_t)のサンプリングをパラメータを用いて行う\n",
    "                pyro.sample(\"obs_x_%d\" % t,\n",
    "                            dist.Bernoulli(emission_probs_t)\n",
    "                                .mask(mini_batch_mask[:, t - 1:t])\n",
    "                                .to_event(1),\n",
    "                            obs=mini_batch[:, t - 1, :])\n",
    "                \n",
    "                #  z_prevの更新\n",
    "                z_prev = z_t\n",
    "\n",
    "    def guide(self, \n",
    "                       mini_batch, # (batch_size, seq_length, feature_size)\n",
    "                       mini_batch_reversed, \n",
    "                       mini_batch_mask, # (batch_size, seq_length)\n",
    "                       mini_batch_seq_lengths,\n",
    "                       annealing_factor=1.0):\n",
    "        T_max = mini_batch.size(1)\n",
    "        \n",
    "        pyro.module(\"dmm\", self) # 自身のクラス(DMM)について記述\n",
    "\n",
    "        # h_0\n",
    "        h_0_contig = self.h_0.expand(1, mini_batch.size(0),\n",
    "                                                              self.rnn.hidden_size).contiguous()\n",
    "\n",
    "        # RNNの出力\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        rnn_output = pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "\n",
    "        # z_prev に z_q_0を設定\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "\n",
    "        # 各データ系列から独立しているのでplateを使う\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch)):\n",
    "            # 潜在変数z_tと観測データxのサンプリングを行う\n",
    "            for t in range(1, T_max + 1):\n",
    "                # 多次元ガウス分布q(z_t | z_{t-1}, x_{t:T})の分布を求める\n",
    "                z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "                z_dist = dist.Normal(z_loc, z_scale)\n",
    "                    \n",
    "                #　z_t ~ q(z_t | z_{t-1}, x_{t:T})\n",
    "                with pyro.poutine.scale(None, annealing_factor):\n",
    "                    z_t = pyro.sample(\"z_%d\" % t,\n",
    "                                                      z_dist.mask(mini_batch_mask[:, t - 1:t])\n",
    "                                                     .to_event(1))                \n",
    "                #  z_prevの更新\n",
    "                z_prev = z_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "dmm = DMM(use_cuda=device)\n",
    "\n",
    "adam_params = {\n",
    "    \"lr\": 0.01, \n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"clip_norm\": 0,\n",
    "    \"lrd\": 0,\n",
    "    \"weight_decay\": 0\n",
    "}\n",
    "\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "svi = SVI(dmm.model, dmm.guide, optimizer, Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Observations in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (0.1.4)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (from Observations) (1.18.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/kajyuuen/.pyenv/versions/3.7.1/lib/python3.7/site-packages (from Observations) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os.path import exists, join\n",
    "from observations import jsb_chorales\n",
    "\n",
    "def process_data(base_path, filename, T_max=160, min_note=21, note_range=88):\n",
    "    output = join(base_path, filename)\n",
    "    if exists(output):\n",
    "        return\n",
    "\n",
    "    print(\"processing raw polyphonic music data...\")\n",
    "    data = jsb_chorales(base_path)\n",
    "    processed_dataset = {}\n",
    "    for split, data_split in zip(['train', 'test', 'valid'], data):\n",
    "        processed_dataset[split] = {}\n",
    "        n_seqs = len(data_split)\n",
    "        processed_dataset[split]['sequence_lengths'] = np.zeros((n_seqs), dtype=np.int32)\n",
    "        processed_dataset[split]['sequences'] = np.zeros((n_seqs, T_max, note_range))\n",
    "        for seq in range(n_seqs):\n",
    "            seq_length = len(data_split[seq])\n",
    "            processed_dataset[split]['sequence_lengths'][seq] = seq_length\n",
    "            for t in range(seq_length):\n",
    "                note_slice = np.array(list(data_split[seq][t])) - min_note\n",
    "                slice_length = len(note_slice)\n",
    "                if slice_length > 0:\n",
    "                    processed_dataset[split]['sequences'][seq, t, note_slice] = np.ones((slice_length))\n",
    "    pickle.dump(processed_dataset, open(output, \"wb\"))\n",
    "    print(\"dumped processed data to %s\" % output)\n",
    "\n",
    "\n",
    "! pip install Observations\n",
    "base_path = '../data'\n",
    "process_data(base_path, \"jsb_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 20\n",
    "\n",
    "jsb_file_loc = \"../data/jsb_processed.pkl\"\n",
    "data = pickle.load(open(jsb_file_loc, \"rb\"))\n",
    "training_seq_lengths = torch.tensor(data['train']['sequence_lengths']).to(device)\n",
    "training_data_sequences = torch.tensor(data['train']['sequences']).float().to(device)\n",
    "\n",
    "test_seq_lengths = torch.tensor(data['test']['sequence_lengths'])\n",
    "test_data_sequences = torch.tensor(data['test']['sequences']).float()\n",
    "\n",
    "val_seq_lengths = torch.tensor(data['valid']['sequence_lengths'])\n",
    "val_data_sequences = torch.tensor(data['valid']['sequences']).float()\n",
    "\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = float(training_seq_lengths.sum())\n",
    "N_mini_batches = int(N_train_data / mini_batch_size +\n",
    "                     int(N_train_data % mini_batch_size > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minibatch(epoch,\n",
    "                                         which_mini_batch,\n",
    "                                         shuffled_indices,\n",
    "                                         annealing_epochs=1000,\n",
    "                                         minimum_annealing_factor=0.1,\n",
    "                                         mini_batch_size=20,\n",
    "                                         cuda=True):\n",
    "    if annealing_epochs > 0 and epoch < annealing_epochs:\n",
    "        # KL アニーリングの適用\n",
    "        min_af = minimum_annealing_factor\n",
    "        annealing_factor = min_af + (1.0 - min_af) * \\\n",
    "            (float(which_mini_batch + epoch * N_mini_batches + 1) /\n",
    "             float(annealing_epochs * N_mini_batches))\n",
    "    else:\n",
    "        annealing_factor = 1.0\n",
    "\n",
    "    # ミニバッチのインデックスの切り出し\n",
    "    mini_batch_start = (which_mini_batch * mini_batch_size)\n",
    "    mini_batch_end = np.min([(which_mini_batch + 1) * mini_batch_size,\n",
    "                             N_train_data])\n",
    "    mini_batch_indices = torch.tensor(shuffled_indices[mini_batch_start:mini_batch_end]).to(cuda)\n",
    "    # ミニバッチの取得\n",
    "    mini_batch, mini_batch_reversed, mini_batch_mask, mini_batch_seq_lengths \\\n",
    "        = get_mini_batch(mini_batch_indices, training_data_sequences,\n",
    "                              training_seq_lengths, cuda=cuda)\n",
    "    # 損失関数の計算\n",
    "    loss = svi.step(mini_batch, mini_batch_reversed, mini_batch_mask,\n",
    "                     mini_batch_seq_lengths, annealing_factor)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_eval_samples = 1\n",
    "def rep(x):\n",
    "    return np.repeat(x, n_eval_samples, axis=0)\n",
    "\n",
    "# get the validation/test data ready for the dmm: pack into sequences, etc.\n",
    "val_seq_lengths = rep(val_seq_lengths)\n",
    "test_seq_lengths = rep(test_seq_lengths)\n",
    "\n",
    "val_batch, val_batch_reversed, val_batch_mask, val_seq_lengths = get_mini_batch(\n",
    "    np.arange(n_eval_samples * val_data_sequences.shape[0]), rep(val_data_sequences),\n",
    "    val_seq_lengths, cuda=device)\n",
    "\n",
    "\n",
    "test_batch, test_batch_reversed, test_batch_mask, test_seq_lengths = \\\n",
    "    get_mini_batch(np.arange(n_eval_samples * test_data_sequences.shape[0]),\n",
    "                        rep(test_data_sequences),\n",
    "                        test_seq_lengths, cuda=device)\n",
    "\n",
    "def do_evaluation():\n",
    "    dmm.rnn.eval()\n",
    "\n",
    "    val_nll = svi.evaluate_loss(val_batch, val_batch_reversed, val_batch_mask,\n",
    "                                 val_seq_lengths) / float(val_seq_lengths.sum())\n",
    "    test_nll = svi.evaluate_loss(test_batch, test_batch_reversed, test_batch_mask,\n",
    "                                  test_seq_lengths) / float(test_seq_lengths.sum())\n",
    "\n",
    "    dmm.rnn.train()\n",
    "    return val_nll, test_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training epoch 0000]  62.5004 \t\t\t\t(dt = 6.146 sec)\n",
      "[val/test epoch 0000]  77.1136  77.0831\n",
      "[training epoch 0001]  62.5064 \t\t\t\t(dt = 6.272 sec)\n",
      "[training epoch 0002]  62.5111 \t\t\t\t(dt = 5.423 sec)\n",
      "[training epoch 0003]  62.5323 \t\t\t\t(dt = 5.646 sec)\n",
      "[training epoch 0004]  62.5561 \t\t\t\t(dt = 5.666 sec)\n",
      "[training epoch 0005]  62.5737 \t\t\t\t(dt = 5.849 sec)\n",
      "[training epoch 0006]  62.5743 \t\t\t\t(dt = 5.608 sec)\n",
      "[training epoch 0007]  62.5961 \t\t\t\t(dt = 6.080 sec)\n",
      "[training epoch 0008]  62.6204 \t\t\t\t(dt = 5.775 sec)\n",
      "[training epoch 0009]  62.6393 \t\t\t\t(dt = 5.593 sec)\n",
      "[training epoch 0010]  62.6415 \t\t\t\t(dt = 5.733 sec)\n",
      "[val/test epoch 0010]  77.1259  77.1433\n",
      "[training epoch 0011]  62.6524 \t\t\t\t(dt = 6.197 sec)\n",
      "[training epoch 0012]  62.6864 \t\t\t\t(dt = 5.179 sec)\n",
      "[training epoch 0013]  62.6961 \t\t\t\t(dt = 5.542 sec)\n",
      "[training epoch 0014]  62.6851 \t\t\t\t(dt = 5.325 sec)\n",
      "[training epoch 0015]  62.7146 \t\t\t\t(dt = 5.440 sec)\n",
      "[training epoch 0016]  62.7305 \t\t\t\t(dt = 5.249 sec)\n",
      "[training epoch 0017]  62.7522 \t\t\t\t(dt = 5.439 sec)\n",
      "[training epoch 0018]  62.7483 \t\t\t\t(dt = 5.463 sec)\n",
      "[training epoch 0019]  62.7792 \t\t\t\t(dt = 5.592 sec)\n",
      "[training epoch 0020]  62.7939 \t\t\t\t(dt = 5.400 sec)\n",
      "[val/test epoch 0020]  77.0490  77.0957\n",
      "[training epoch 0021]  62.7948 \t\t\t\t(dt = 6.342 sec)\n",
      "[training epoch 0022]  62.8052 \t\t\t\t(dt = 5.416 sec)\n",
      "[training epoch 0023]  62.8432 \t\t\t\t(dt = 5.691 sec)\n",
      "[training epoch 0024]  62.8415 \t\t\t\t(dt = 5.604 sec)\n",
      "[training epoch 0025]  62.8577 \t\t\t\t(dt = 5.440 sec)\n",
      "[training epoch 0026]  62.8899 \t\t\t\t(dt = 5.453 sec)\n",
      "[training epoch 0027]  62.8746 \t\t\t\t(dt = 5.544 sec)\n",
      "[training epoch 0028]  62.8979 \t\t\t\t(dt = 5.471 sec)\n",
      "[training epoch 0029]  62.9210 \t\t\t\t(dt = 5.446 sec)\n",
      "[training epoch 0030]  62.9278 \t\t\t\t(dt = 5.494 sec)\n",
      "[val/test epoch 0030]  77.0388  77.0311\n",
      "[training epoch 0031]  62.9343 \t\t\t\t(dt = 6.295 sec)\n",
      "[training epoch 0032]  62.9552 \t\t\t\t(dt = 5.498 sec)\n",
      "[training epoch 0033]  62.9763 \t\t\t\t(dt = 5.562 sec)\n",
      "[training epoch 0034]  62.9992 \t\t\t\t(dt = 5.318 sec)\n",
      "[training epoch 0035]  63.0055 \t\t\t\t(dt = 5.335 sec)\n",
      "[training epoch 0036]  63.0194 \t\t\t\t(dt = 5.501 sec)\n",
      "[training epoch 0037]  63.0477 \t\t\t\t(dt = 5.312 sec)\n",
      "[training epoch 0038]  63.0505 \t\t\t\t(dt = 5.391 sec)\n",
      "[training epoch 0039]  63.0438 \t\t\t\t(dt = 5.410 sec)\n",
      "[training epoch 0040]  63.0816 \t\t\t\t(dt = 5.773 sec)\n",
      "[val/test epoch 0040]  77.0394  77.0292\n",
      "[training epoch 0041]  63.0928 \t\t\t\t(dt = 6.214 sec)\n",
      "[training epoch 0042]  63.1068 \t\t\t\t(dt = 5.298 sec)\n",
      "[training epoch 0043]  63.1263 \t\t\t\t(dt = 5.369 sec)\n",
      "[training epoch 0044]  63.1352 \t\t\t\t(dt = 5.796 sec)\n",
      "[training epoch 0045]  63.1509 \t\t\t\t(dt = 5.837 sec)\n",
      "[training epoch 0046]  63.1550 \t\t\t\t(dt = 5.568 sec)\n",
      "[training epoch 0047]  63.1852 \t\t\t\t(dt = 5.464 sec)\n",
      "[training epoch 0048]  63.1800 \t\t\t\t(dt = 5.328 sec)\n",
      "[training epoch 0049]  63.2100 \t\t\t\t(dt = 5.372 sec)\n",
      "[training epoch 0050]  63.2222 \t\t\t\t(dt = 5.332 sec)\n",
      "[val/test epoch 0050]  77.1261  77.0198\n",
      "[training epoch 0051]  63.2363 \t\t\t\t(dt = 6.470 sec)\n",
      "[training epoch 0052]  63.2404 \t\t\t\t(dt = 5.483 sec)\n",
      "[training epoch 0053]  63.2652 \t\t\t\t(dt = 5.353 sec)\n",
      "[training epoch 0054]  63.2901 \t\t\t\t(dt = 5.469 sec)\n",
      "[training epoch 0055]  63.3015 \t\t\t\t(dt = 5.618 sec)\n",
      "[training epoch 0056]  63.3259 \t\t\t\t(dt = 5.491 sec)\n",
      "[training epoch 0057]  63.3408 \t\t\t\t(dt = 5.690 sec)\n",
      "[training epoch 0058]  63.3295 \t\t\t\t(dt = 5.856 sec)\n",
      "[training epoch 0059]  63.3459 \t\t\t\t(dt = 5.546 sec)\n",
      "[training epoch 0060]  63.3625 \t\t\t\t(dt = 5.592 sec)\n",
      "[val/test epoch 0060]  77.0536  77.1706\n",
      "[training epoch 0061]  63.3674 \t\t\t\t(dt = 6.120 sec)\n",
      "[training epoch 0062]  63.3800 \t\t\t\t(dt = 5.488 sec)\n",
      "[training epoch 0063]  63.4331 \t\t\t\t(dt = 5.860 sec)\n",
      "[training epoch 0064]  63.4302 \t\t\t\t(dt = 5.681 sec)\n",
      "[training epoch 0065]  63.4544 \t\t\t\t(dt = 5.634 sec)\n",
      "[training epoch 0066]  63.4673 \t\t\t\t(dt = 5.660 sec)\n",
      "[training epoch 0067]  63.4547 \t\t\t\t(dt = 5.425 sec)\n",
      "[training epoch 0068]  63.4748 \t\t\t\t(dt = 5.369 sec)\n",
      "[training epoch 0069]  63.4916 \t\t\t\t(dt = 5.644 sec)\n",
      "[training epoch 0070]  63.5119 \t\t\t\t(dt = 5.371 sec)\n",
      "[val/test epoch 0070]  77.0716  77.0956\n",
      "[training epoch 0071]  63.5343 \t\t\t\t(dt = 5.884 sec)\n",
      "[training epoch 0072]  63.5516 \t\t\t\t(dt = 5.326 sec)\n",
      "[training epoch 0073]  63.5649 \t\t\t\t(dt = 5.470 sec)\n",
      "[training epoch 0074]  63.5703 \t\t\t\t(dt = 5.486 sec)\n",
      "[training epoch 0075]  63.6038 \t\t\t\t(dt = 5.337 sec)\n",
      "[training epoch 0076]  63.6018 \t\t\t\t(dt = 5.316 sec)\n",
      "[training epoch 0077]  63.6055 \t\t\t\t(dt = 5.389 sec)\n",
      "[training epoch 0078]  63.6321 \t\t\t\t(dt = 5.452 sec)\n",
      "[training epoch 0079]  63.6239 \t\t\t\t(dt = 5.374 sec)\n",
      "[training epoch 0080]  63.6603 \t\t\t\t(dt = 5.429 sec)\n",
      "[val/test epoch 0080]  77.0462  77.0672\n",
      "[training epoch 0081]  63.6704 \t\t\t\t(dt = 6.060 sec)\n",
      "[training epoch 0082]  63.6711 \t\t\t\t(dt = 5.494 sec)\n",
      "[training epoch 0083]  63.7016 \t\t\t\t(dt = 5.616 sec)\n",
      "[training epoch 0084]  63.7279 \t\t\t\t(dt = 5.596 sec)\n",
      "[training epoch 0085]  63.7230 \t\t\t\t(dt = 5.548 sec)\n",
      "[training epoch 0086]  63.7486 \t\t\t\t(dt = 5.594 sec)\n",
      "[training epoch 0087]  63.7473 \t\t\t\t(dt = 5.618 sec)\n",
      "[training epoch 0088]  63.7732 \t\t\t\t(dt = 5.604 sec)\n",
      "[training epoch 0089]  63.7690 \t\t\t\t(dt = 5.768 sec)\n",
      "[training epoch 0090]  63.8018 \t\t\t\t(dt = 5.823 sec)\n",
      "[val/test epoch 0090]  77.0062  77.1516\n",
      "[training epoch 0091]  63.8238 \t\t\t\t(dt = 6.588 sec)\n",
      "[training epoch 0092]  63.8359 \t\t\t\t(dt = 6.089 sec)\n",
      "[training epoch 0093]  63.8373 \t\t\t\t(dt = 5.941 sec)\n",
      "[training epoch 0094]  63.8604 \t\t\t\t(dt = 5.989 sec)\n",
      "[training epoch 0095]  63.8752 \t\t\t\t(dt = 5.663 sec)\n",
      "[training epoch 0096]  63.8695 \t\t\t\t(dt = 6.019 sec)\n",
      "[training epoch 0097]  63.8839 \t\t\t\t(dt = 6.222 sec)\n",
      "[training epoch 0098]  63.9156 \t\t\t\t(dt = 5.793 sec)\n",
      "[training epoch 0099]  63.9111 \t\t\t\t(dt = 5.687 sec)\n",
      "[training epoch 0100]  63.9393 \t\t\t\t(dt = 5.959 sec)\n",
      "[val/test epoch 0100]  77.0446  77.1473\n",
      "[training epoch 0101]  63.9604 \t\t\t\t(dt = 6.703 sec)\n",
      "[training epoch 0102]  63.9661 \t\t\t\t(dt = 6.195 sec)\n",
      "[training epoch 0103]  63.9948 \t\t\t\t(dt = 5.899 sec)\n",
      "[training epoch 0104]  63.9901 \t\t\t\t(dt = 6.124 sec)\n",
      "[training epoch 0105]  64.0260 \t\t\t\t(dt = 6.097 sec)\n",
      "[training epoch 0106]  64.0426 \t\t\t\t(dt = 6.111 sec)\n",
      "[training epoch 0107]  64.0700 \t\t\t\t(dt = 6.217 sec)\n",
      "[training epoch 0108]  64.0685 \t\t\t\t(dt = 5.932 sec)\n",
      "[training epoch 0109]  64.0546 \t\t\t\t(dt = 5.745 sec)\n",
      "[training epoch 0110]  64.0900 \t\t\t\t(dt = 5.340 sec)\n",
      "[val/test epoch 0110]  77.0745  76.9900\n",
      "[training epoch 0111]  64.1043 \t\t\t\t(dt = 6.420 sec)\n",
      "[training epoch 0112]  64.0996 \t\t\t\t(dt = 5.421 sec)\n",
      "[training epoch 0113]  64.1149 \t\t\t\t(dt = 5.937 sec)\n",
      "[training epoch 0114]  64.1472 \t\t\t\t(dt = 5.696 sec)\n",
      "[training epoch 0115]  64.1527 \t\t\t\t(dt = 5.765 sec)\n",
      "[training epoch 0116]  64.1810 \t\t\t\t(dt = 5.849 sec)\n",
      "[training epoch 0117]  64.1765 \t\t\t\t(dt = 5.507 sec)\n",
      "[training epoch 0118]  64.1961 \t\t\t\t(dt = 5.669 sec)\n",
      "[training epoch 0119]  64.2167 \t\t\t\t(dt = 5.674 sec)\n",
      "[training epoch 0120]  64.2449 \t\t\t\t(dt = 5.846 sec)\n",
      "[val/test epoch 0120]  77.1175  77.0096\n",
      "[training epoch 0121]  64.2211 \t\t\t\t(dt = 6.432 sec)\n",
      "[training epoch 0122]  64.2595 \t\t\t\t(dt = 5.820 sec)\n",
      "[training epoch 0123]  64.2886 \t\t\t\t(dt = 5.805 sec)\n",
      "[training epoch 0124]  64.2969 \t\t\t\t(dt = 6.016 sec)\n",
      "[training epoch 0125]  64.3222 \t\t\t\t(dt = 5.915 sec)\n",
      "[training epoch 0126]  64.3030 \t\t\t\t(dt = 5.862 sec)\n",
      "[training epoch 0127]  64.3412 \t\t\t\t(dt = 5.955 sec)\n",
      "[training epoch 0128]  64.3427 \t\t\t\t(dt = 5.557 sec)\n",
      "[training epoch 0129]  64.3525 \t\t\t\t(dt = 5.899 sec)\n",
      "[training epoch 0130]  64.4106 \t\t\t\t(dt = 5.485 sec)\n",
      "[val/test epoch 0130]  77.1639  76.9993\n",
      "[training epoch 0131]  64.3883 \t\t\t\t(dt = 6.386 sec)\n",
      "[training epoch 0132]  64.3965 \t\t\t\t(dt = 5.815 sec)\n",
      "[training epoch 0133]  64.3978 \t\t\t\t(dt = 5.437 sec)\n",
      "[training epoch 0134]  64.4340 \t\t\t\t(dt = 5.683 sec)\n",
      "[training epoch 0135]  64.4349 \t\t\t\t(dt = 5.695 sec)\n",
      "[training epoch 0136]  64.4647 \t\t\t\t(dt = 5.802 sec)\n",
      "[training epoch 0137]  64.4768 \t\t\t\t(dt = 5.729 sec)\n",
      "[training epoch 0138]  64.4971 \t\t\t\t(dt = 5.540 sec)\n",
      "[training epoch 0139]  64.4885 \t\t\t\t(dt = 5.723 sec)\n",
      "[training epoch 0140]  64.5212 \t\t\t\t(dt = 5.640 sec)\n",
      "[val/test epoch 0140]  77.1209  77.0116\n",
      "[training epoch 0141]  64.5554 \t\t\t\t(dt = 6.625 sec)\n",
      "[training epoch 0142]  64.5395 \t\t\t\t(dt = 6.143 sec)\n",
      "[training epoch 0143]  64.5650 \t\t\t\t(dt = 5.596 sec)\n",
      "[training epoch 0144]  64.5809 \t\t\t\t(dt = 6.132 sec)\n",
      "[training epoch 0145]  64.6107 \t\t\t\t(dt = 5.992 sec)\n",
      "[training epoch 0146]  64.6055 \t\t\t\t(dt = 5.810 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training epoch 0147]  64.6222 \t\t\t\t(dt = 5.761 sec)\n",
      "[training epoch 0148]  64.6404 \t\t\t\t(dt = 5.547 sec)\n",
      "[training epoch 0149]  64.6455 \t\t\t\t(dt = 5.567 sec)\n",
      "[training epoch 0150]  64.6669 \t\t\t\t(dt = 5.395 sec)\n",
      "[val/test epoch 0150]  77.0269  76.9569\n",
      "[training epoch 0151]  64.6908 \t\t\t\t(dt = 6.704 sec)\n",
      "[training epoch 0152]  64.6957 \t\t\t\t(dt = 5.407 sec)\n",
      "[training epoch 0153]  64.7130 \t\t\t\t(dt = 5.281 sec)\n",
      "[training epoch 0154]  64.7141 \t\t\t\t(dt = 5.348 sec)\n",
      "[training epoch 0155]  64.7203 \t\t\t\t(dt = 5.763 sec)\n",
      "[training epoch 0156]  64.7459 \t\t\t\t(dt = 5.847 sec)\n",
      "[training epoch 0157]  64.7815 \t\t\t\t(dt = 5.488 sec)\n",
      "[training epoch 0158]  64.7696 \t\t\t\t(dt = 5.404 sec)\n",
      "[training epoch 0159]  64.7999 \t\t\t\t(dt = 5.740 sec)\n",
      "[training epoch 0160]  64.8000 \t\t\t\t(dt = 5.808 sec)\n",
      "[val/test epoch 0160]  77.0329  77.0555\n",
      "[training epoch 0161]  64.8231 \t\t\t\t(dt = 6.115 sec)\n",
      "[training epoch 0162]  64.8397 \t\t\t\t(dt = 5.622 sec)\n",
      "[training epoch 0163]  64.8741 \t\t\t\t(dt = 5.652 sec)\n",
      "[training epoch 0164]  64.8522 \t\t\t\t(dt = 5.858 sec)\n",
      "[training epoch 0165]  64.8914 \t\t\t\t(dt = 6.017 sec)\n",
      "[training epoch 0166]  64.9049 \t\t\t\t(dt = 5.807 sec)\n",
      "[training epoch 0167]  64.9057 \t\t\t\t(dt = 5.918 sec)\n",
      "[training epoch 0168]  64.9193 \t\t\t\t(dt = 6.165 sec)\n",
      "[training epoch 0169]  64.9591 \t\t\t\t(dt = 5.644 sec)\n",
      "[training epoch 0170]  64.9475 \t\t\t\t(dt = 5.966 sec)\n",
      "[val/test epoch 0170]  77.0443  77.1220\n",
      "[training epoch 0171]  64.9749 \t\t\t\t(dt = 6.345 sec)\n",
      "[training epoch 0172]  64.9624 \t\t\t\t(dt = 5.552 sec)\n",
      "[training epoch 0173]  65.0030 \t\t\t\t(dt = 5.762 sec)\n",
      "[training epoch 0174]  65.0133 \t\t\t\t(dt = 5.929 sec)\n",
      "[training epoch 0175]  65.0276 \t\t\t\t(dt = 5.955 sec)\n",
      "[training epoch 0176]  65.0432 \t\t\t\t(dt = 5.456 sec)\n",
      "[training epoch 0177]  65.0479 \t\t\t\t(dt = 5.544 sec)\n",
      "[training epoch 0178]  65.0744 \t\t\t\t(dt = 5.314 sec)\n",
      "[training epoch 0179]  65.1167 \t\t\t\t(dt = 5.651 sec)\n",
      "[training epoch 0180]  65.1199 \t\t\t\t(dt = 5.232 sec)\n",
      "[val/test epoch 0180]  77.2121  77.1826\n",
      "[training epoch 0181]  65.1179 \t\t\t\t(dt = 6.102 sec)\n",
      "[training epoch 0182]  65.1265 \t\t\t\t(dt = 5.474 sec)\n",
      "[training epoch 0183]  65.1280 \t\t\t\t(dt = 5.146 sec)\n",
      "[training epoch 0184]  65.1622 \t\t\t\t(dt = 5.431 sec)\n",
      "[training epoch 0185]  65.1607 \t\t\t\t(dt = 5.493 sec)\n",
      "[training epoch 0186]  65.1778 \t\t\t\t(dt = 5.737 sec)\n",
      "[training epoch 0187]  65.2176 \t\t\t\t(dt = 5.729 sec)\n",
      "[training epoch 0188]  65.2137 \t\t\t\t(dt = 5.392 sec)\n",
      "[training epoch 0189]  65.2223 \t\t\t\t(dt = 5.606 sec)\n",
      "[training epoch 0190]  65.2326 \t\t\t\t(dt = 5.970 sec)\n",
      "[val/test epoch 0190]  77.1122  77.0944\n",
      "[training epoch 0191]  65.2405 \t\t\t\t(dt = 6.270 sec)\n",
      "[training epoch 0192]  65.2482 \t\t\t\t(dt = 5.887 sec)\n",
      "[training epoch 0193]  65.2732 \t\t\t\t(dt = 5.619 sec)\n",
      "[training epoch 0194]  65.3030 \t\t\t\t(dt = 5.725 sec)\n",
      "[training epoch 0195]  65.3041 \t\t\t\t(dt = 5.593 sec)\n",
      "[training epoch 0196]  65.3428 \t\t\t\t(dt = 5.526 sec)\n",
      "[training epoch 0197]  65.3323 \t\t\t\t(dt = 5.933 sec)\n",
      "[training epoch 0198]  65.3461 \t\t\t\t(dt = 5.429 sec)\n",
      "[training epoch 0199]  65.3782 \t\t\t\t(dt = 5.578 sec)\n",
      "[training epoch 0200]  65.3977 \t\t\t\t(dt = 5.671 sec)\n",
      "[val/test epoch 0200]  77.0448  77.0536\n",
      "[training epoch 0201]  65.3989 \t\t\t\t(dt = 6.555 sec)\n",
      "[training epoch 0202]  65.4256 \t\t\t\t(dt = 5.888 sec)\n",
      "[training epoch 0203]  65.4403 \t\t\t\t(dt = 5.645 sec)\n",
      "[training epoch 0204]  65.4569 \t\t\t\t(dt = 5.623 sec)\n",
      "[training epoch 0205]  65.4678 \t\t\t\t(dt = 5.499 sec)\n",
      "[training epoch 0206]  65.4743 \t\t\t\t(dt = 5.718 sec)\n",
      "[training epoch 0207]  65.4787 \t\t\t\t(dt = 5.755 sec)\n",
      "[training epoch 0208]  65.5184 \t\t\t\t(dt = 5.629 sec)\n",
      "[training epoch 0209]  65.5160 \t\t\t\t(dt = 5.863 sec)\n",
      "[training epoch 0210]  65.5557 \t\t\t\t(dt = 5.784 sec)\n",
      "[val/test epoch 0210]  77.0345  77.1463\n",
      "[training epoch 0211]  65.5397 \t\t\t\t(dt = 6.052 sec)\n",
      "[training epoch 0212]  65.5403 \t\t\t\t(dt = 5.437 sec)\n",
      "[training epoch 0213]  65.5708 \t\t\t\t(dt = 5.315 sec)\n",
      "[training epoch 0214]  65.6080 \t\t\t\t(dt = 5.442 sec)\n",
      "[training epoch 0215]  65.6123 \t\t\t\t(dt = 5.442 sec)\n",
      "[training epoch 0216]  65.6203 \t\t\t\t(dt = 5.360 sec)\n",
      "[training epoch 0217]  65.6378 \t\t\t\t(dt = 5.377 sec)\n",
      "[training epoch 0218]  65.6338 \t\t\t\t(dt = 5.659 sec)\n",
      "[training epoch 0219]  65.6671 \t\t\t\t(dt = 5.513 sec)\n",
      "[training epoch 0220]  65.6641 \t\t\t\t(dt = 5.143 sec)\n",
      "[val/test epoch 0220]  77.1353  77.0189\n",
      "[training epoch 0221]  65.6725 \t\t\t\t(dt = 6.167 sec)\n",
      "[training epoch 0222]  65.6973 \t\t\t\t(dt = 5.560 sec)\n",
      "[training epoch 0223]  65.6898 \t\t\t\t(dt = 5.635 sec)\n",
      "[training epoch 0224]  65.7439 \t\t\t\t(dt = 5.221 sec)\n",
      "[training epoch 0225]  65.7264 \t\t\t\t(dt = 5.376 sec)\n",
      "[training epoch 0226]  65.7794 \t\t\t\t(dt = 5.416 sec)\n",
      "[training epoch 0227]  65.7728 \t\t\t\t(dt = 5.711 sec)\n",
      "[training epoch 0228]  65.7995 \t\t\t\t(dt = 5.358 sec)\n",
      "[training epoch 0229]  65.8127 \t\t\t\t(dt = 5.789 sec)\n",
      "[training epoch 0230]  65.8178 \t\t\t\t(dt = 5.676 sec)\n",
      "[val/test epoch 0230]  77.0130  76.9876\n",
      "[training epoch 0231]  65.8083 \t\t\t\t(dt = 6.142 sec)\n",
      "[training epoch 0232]  65.8567 \t\t\t\t(dt = 5.602 sec)\n",
      "[training epoch 0233]  65.8393 \t\t\t\t(dt = 5.618 sec)\n",
      "[training epoch 0234]  65.8773 \t\t\t\t(dt = 5.564 sec)\n",
      "[training epoch 0235]  65.8577 \t\t\t\t(dt = 5.229 sec)\n",
      "[training epoch 0236]  65.9007 \t\t\t\t(dt = 5.240 sec)\n",
      "[training epoch 0237]  65.8961 \t\t\t\t(dt = 5.199 sec)\n",
      "[training epoch 0238]  65.9283 \t\t\t\t(dt = 5.319 sec)\n",
      "[training epoch 0239]  65.9335 \t\t\t\t(dt = 5.563 sec)\n",
      "[training epoch 0240]  65.9544 \t\t\t\t(dt = 5.396 sec)\n",
      "[val/test epoch 0240]  77.0734  77.0543\n",
      "[training epoch 0241]  65.9851 \t\t\t\t(dt = 6.366 sec)\n",
      "[training epoch 0242]  65.9763 \t\t\t\t(dt = 5.064 sec)\n",
      "[training epoch 0243]  65.9902 \t\t\t\t(dt = 5.501 sec)\n",
      "[training epoch 0244]  66.0168 \t\t\t\t(dt = 5.316 sec)\n",
      "[training epoch 0245]  66.0475 \t\t\t\t(dt = 5.592 sec)\n",
      "[training epoch 0246]  66.0548 \t\t\t\t(dt = 5.142 sec)\n",
      "[training epoch 0247]  66.0524 \t\t\t\t(dt = 5.366 sec)\n",
      "[training epoch 0248]  66.0954 \t\t\t\t(dt = 5.398 sec)\n",
      "[training epoch 0249]  66.0846 \t\t\t\t(dt = 5.595 sec)\n",
      "[training epoch 0250]  66.0910 \t\t\t\t(dt = 5.487 sec)\n",
      "[val/test epoch 0250]  77.0636  77.0819\n",
      "[training epoch 0251]  66.1240 \t\t\t\t(dt = 6.103 sec)\n",
      "[training epoch 0252]  66.1333 \t\t\t\t(dt = 5.458 sec)\n",
      "[training epoch 0253]  66.1427 \t\t\t\t(dt = 5.989 sec)\n",
      "[training epoch 0254]  66.1556 \t\t\t\t(dt = 5.402 sec)\n",
      "[training epoch 0255]  66.1558 \t\t\t\t(dt = 5.472 sec)\n",
      "[training epoch 0256]  66.1842 \t\t\t\t(dt = 5.459 sec)\n",
      "[training epoch 0257]  66.1856 \t\t\t\t(dt = 5.304 sec)\n",
      "[training epoch 0258]  66.2304 \t\t\t\t(dt = 5.346 sec)\n",
      "[training epoch 0259]  66.2302 \t\t\t\t(dt = 5.485 sec)\n",
      "[training epoch 0260]  66.2741 \t\t\t\t(dt = 5.549 sec)\n",
      "[val/test epoch 0260]  77.1360  77.1114\n",
      "[training epoch 0261]  66.2633 \t\t\t\t(dt = 5.851 sec)\n",
      "[training epoch 0262]  66.2920 \t\t\t\t(dt = 5.647 sec)\n",
      "[training epoch 0263]  66.3153 \t\t\t\t(dt = 5.361 sec)\n",
      "[training epoch 0264]  66.3264 \t\t\t\t(dt = 5.436 sec)\n",
      "[training epoch 0265]  66.3142 \t\t\t\t(dt = 5.057 sec)\n",
      "[training epoch 0266]  66.3504 \t\t\t\t(dt = 5.533 sec)\n",
      "[training epoch 0267]  66.3306 \t\t\t\t(dt = 5.518 sec)\n",
      "[training epoch 0268]  66.3602 \t\t\t\t(dt = 5.369 sec)\n",
      "[training epoch 0269]  66.3981 \t\t\t\t(dt = 5.609 sec)\n",
      "[training epoch 0270]  66.4103 \t\t\t\t(dt = 5.837 sec)\n",
      "[val/test epoch 0270]  77.1508  77.0254\n",
      "[training epoch 0271]  66.4019 \t\t\t\t(dt = 6.172 sec)\n",
      "[training epoch 0272]  66.4290 \t\t\t\t(dt = 5.805 sec)\n",
      "[training epoch 0273]  66.4620 \t\t\t\t(dt = 5.693 sec)\n",
      "[training epoch 0274]  66.4561 \t\t\t\t(dt = 5.850 sec)\n",
      "[training epoch 0275]  66.4706 \t\t\t\t(dt = 5.435 sec)\n",
      "[training epoch 0276]  66.4800 \t\t\t\t(dt = 5.655 sec)\n",
      "[training epoch 0277]  66.5227 \t\t\t\t(dt = 5.698 sec)\n",
      "[training epoch 0278]  66.4801 \t\t\t\t(dt = 5.512 sec)\n",
      "[training epoch 0279]  66.5195 \t\t\t\t(dt = 5.369 sec)\n",
      "[training epoch 0280]  66.5254 \t\t\t\t(dt = 5.311 sec)\n",
      "[val/test epoch 0280]  76.9567  77.0303\n",
      "[training epoch 0281]  66.5403 \t\t\t\t(dt = 6.224 sec)\n",
      "[training epoch 0282]  66.5556 \t\t\t\t(dt = 5.550 sec)\n",
      "[training epoch 0283]  66.5464 \t\t\t\t(dt = 5.690 sec)\n",
      "[training epoch 0284]  66.5890 \t\t\t\t(dt = 5.625 sec)\n",
      "[training epoch 0285]  66.6140 \t\t\t\t(dt = 5.443 sec)\n",
      "[training epoch 0286]  66.6196 \t\t\t\t(dt = 5.544 sec)\n",
      "[training epoch 0287]  66.6484 \t\t\t\t(dt = 5.570 sec)\n",
      "[training epoch 0288]  66.6707 \t\t\t\t(dt = 5.413 sec)\n",
      "[training epoch 0289]  66.6656 \t\t\t\t(dt = 5.394 sec)\n",
      "[training epoch 0290]  66.6628 \t\t\t\t(dt = 5.249 sec)\n",
      "[val/test epoch 0290]  77.0134  76.9657\n",
      "[training epoch 0291]  66.7015 \t\t\t\t(dt = 6.070 sec)\n",
      "[training epoch 0292]  66.7507 \t\t\t\t(dt = 5.373 sec)\n",
      "[training epoch 0293]  66.7176 \t\t\t\t(dt = 5.445 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training epoch 0294]  66.7205 \t\t\t\t(dt = 5.990 sec)\n",
      "[training epoch 0295]  66.7345 \t\t\t\t(dt = 5.360 sec)\n",
      "[training epoch 0296]  66.7575 \t\t\t\t(dt = 5.643 sec)\n",
      "[training epoch 0297]  66.8045 \t\t\t\t(dt = 5.801 sec)\n",
      "[training epoch 0298]  66.7883 \t\t\t\t(dt = 5.648 sec)\n",
      "[training epoch 0299]  66.8289 \t\t\t\t(dt = 5.567 sec)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "val_test_frequency = 10\n",
    "train_losses, val_losses, test_losses = [], [], []\n",
    "times = [time.time()]\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_nll = 0.0\n",
    "\n",
    "    # エポックごとにバッチのシャッフルする\n",
    "    shuffled_indices = np.arange(N_train_data)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "\n",
    "    # ミニバッチの計算\n",
    "    for which_mini_batch in range(N_mini_batches):\n",
    "        epoch_nll += process_minibatch(epoch, which_mini_batch, shuffled_indices, cuda=device)\n",
    "    \n",
    "    #  ログの表示\n",
    "    train_losses.append(epoch_nll / N_train_time_slices)\n",
    "    times.append(time.time())\n",
    "    epoch_time = times[-1] - times[-2]\n",
    "    print(\"[training epoch %04d]  %.4f \\t\\t\\t\\t(dt = %.3f sec)\" %\n",
    "        (epoch, epoch_nll / N_train_time_slices, epoch_time))\n",
    "\n",
    "    if val_test_frequency > 0 and epoch % val_test_frequency == 0:\n",
    "            val_nll, test_nll = do_evaluation()\n",
    "            val_losses.append(val_nll)\n",
    "            test_losses.append(test_nll)\n",
    "            print(\"[val/test epoch %04d]  %.4f  %.4f\" % (epoch, val_nll, test_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b3a5acae9e8>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Train ELBO\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "\n",
    "plt.plot(range(num_epochs), train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b3a5ad46400>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhc9XX4//fRrtEyY0m2JXmTd1vGxoCBELYkbIEQIGmaQPalSbMnTdOW9vu03zS/9tuU7knTptAspA2EJJBAUoohxAQIBGOMbfAGlm3JtmRL1shaRstImvP7496Rx/JImn2Rz+t59Hjmzp3R53oknfls54iqYowxxiSjINsNMMYYk/8smBhjjEmaBRNjjDFJs2BijDEmaRZMjDHGJM2CiTHGmKRZMDEmBUSkSURURIrc+/8rIh+K5VxjZgMLJsYAIvKYiHw1yvFbReR4vH/4VfVGVb03wbYcFpFrE3muMdliwcQYx73A+0VEJh3/APADVR3LQpuMyRsWTIxx/AyoBa4MHxCROcDNwPfd+28TkZdFpE9EjojIV6Z6MRF5SkR+z71dKCJ/LyInReQg8LZEGykiHxeRAyLiF5FHRKTRPS4i8k8i0um27xUROc997CYR2SMi/SJyTES+nOj3N2YqFkyMAVR1CPgR8MGIw+8G9qnqTvd+wH3chxMQPiUit8Xw8h/HCUoXAJuAdyXSRhF5C/A3brsagFbgh+7D1wNXAasAr3tOt/vYt4HfV9Uq4DzgV4l8f2OmY8HEmNPuBd4lImXu/Q+6xwBQ1adU9RVVDanqLuB+4OoYXvfdwD+r6hFV9eMEhES8D/iOqm5X1RHgT4HLRKQJGAWqgDWAqOpeVe1wnzcKNItItar2qOr2BL+/MVOyYGKMS1WfBU4Ct4nIcuAS4L7w4yJyqYhsEZEuEekFPgnUxfDSjcCRiPutCTaxMfK5qjqA0/tYoKq/Av4V+CbQKSJ3i0i1e+rvADcBrSLyaxG5LMHvb8yULJgYc6bv4/RI3g9sVtUTEY/dBzwCLFJVL/AtYPKEfTQdwKKI+4sTbFs7sCR8R0QqcOZ5jgGo6tdV9SKgGWe464/c4y+q6q3APJy5oR8l+P2NmZIFE2PO9H3gWpx5jslLe6sAv6oOi8glwHtjfM0fAZ8XkYXupP6dMTynWETKIr6KcIbVPiIiG0WkFPh/wAuqelhELnZ7TsU4czvDQEhESkTkfSLiVdVRoA8IxdhuY2JmwcSYCKp6GHgOqMDphUT6NPBVEekH/oLYP+HfA2wGdgLbgYdieM6jwFDE11dU9ZfAnwMP4vR2lgO3u+dXu9+nB2corBv4O/exDwCHRaQPZ2jufTG225iYiRXHMsYYkyzrmRhjjEmaBRNjjDFJs2BijDEmaRZMjDHGJO2cSIFdV1enTU1N2W6GMcbklZdeeumkqs6N5dxzIpg0NTWxbdu2bDfDGGPyiojEnK3BhrmMMcYkzYKJMcaYpFkwMcYYkzQLJsYYY5JmwcQYY0zSLJgYY4xJmgUTY4wxSbNgYoyZsO94H7892D3zicZMYsHEGDPhHx9/jS//eGe2m2HykAUTY8yEkwMjtJ8aIjhmxRhNfCyYGGMm+ANBQgpHewaz3RSTZyyYGGMm+ANBANr8FkxMfCyYGGMAGB0P0Tc8BlgwMfGzYGKMAaDH7ZUAtHZbMDHxSVsKehFZDTwQcWgZ8BfAZcBq95gPOKWqGyc9dxHwfWA+oMDdqvov7mM17us2AYeBd6tqT7quw5hzRbcFE5OEtPVMVHW/qm50A8VFwCDwU1V9T8TxB4GHojx9DPhDVW0G3gB8RkSa3cfuBJ5U1ZXAk+59Y0ySwj2T6rIijtgwl4lTpoa5rgFaVHWi0IqICPBu4P7JJ6tqh6pud2/3A3uBBe7DtwL3urfvBW5LY7uNOWeEeybnL/LR5h9EVbPcIpNPMhVMbufsoHElcEJVX5/uiSLSBFwAvOAemq+qHe7t4zhDYcaYJIVXcl2wyMfQ6Dhd/SNZbpHJJ2kPJiJSAtwC/HjSQ3cQpVcy6bmVOENhX1TVvsmPq/PRKerHJxH5hIhsE5FtXV1dCbXdmHOJP6JnAtBqQ10mDpnomdwIbFfVE+EDIlIEvJMzJ+jPICLFOIHkB6oaOa9yQkQa3HMagM5oz1fVu1V1k6pumjt3bgouw5jZzR8I4vMUs7SuAoA2m4Q3cchEMInWA7kW2KeqR6M9wZ1P+TawV1X/cdLDjwAfcm9/CHg4hW015pzlDwSpqShh4RwPItYzMfFJazARkQrgOs5esXXWHIqINIrIo+7dy4EPAG8RkR3u103uY18DrhOR13GC0tfSdgHGnEP8gSA1nhJKigpo9JbT1h3IdpNMHknbPhMAVQ0AtVGOfzjKsXbgJvf2s4BM8ZrdOKvDjDEp5A8EWVLrAWBxjcd2wZu42A54YwzgLA2urSwBYEmtBRMTHwsmxhhUlZ7BIHM8TjBZXOvh5ECQgZGxLLfM5AsLJsYY+obGGA8pNRVuMKlxhrtsRZeJlQUTYwzdAWeD4sQwV427PNiGukyMLJgYYyY2LEYOcwG0+W1Fl4mNBRNjzEQwqa0oBcBbXozPU2zZg03MLJgYYyaCSY07zAW2PNjEx4KJMWYiY3CNx4KJSYwFE2MMPYEg5cWFlJcUThxbUuvhWM8QY+OhLLbM5AsLJsaYibxckRbXeBgLKe2nhrPUKpNPLJgYY87Y/R622F0e3GorukwMLJgYY87Y/R62ZGJ5sM2bmJlZMDHG0D0QpHbSMFd9dRklhQW2C97ExIKJMSbqnElBgbCwptz2mpiYWDAx5hw3FBxnaHScOZOCCcASWx5sYmTBxJhznH8wvPs9SjCpraDNP4iqZrpZJs9YMDHmHOcfcDcsRgkmi2s8DIyMTeyQN2YqFkyMOceFeyZTBROwevBmZhZMjDnH+d3089GCSXh58BELJmYGFkyMOcd1D5yZMTjSonDPxFZ0mRlYMDHmHOcPBCksEKrKis56rKy4kPrqMgsmZkYWTIxJwpFZsNIpvPu9oECiPu5kD7aUKmZ6FkyMSdCBzn6u/rstPLT9WLabkpRou98jLa61vSZmZhZMjEnQE3s6CSn8zysd2W5KUqLtfo+0pMbDib4RhkfHM9gqk28smBiToC37OgF49vWTDIyMZbk1ifMPTh9MFlvCRxMDCybGJKB3cJSX2nq4pKmG4HiIp/Z3ZrtJCZupZ7LYVnSZGFgwMSYBT7/exXhI+fINq6mtKOHx3Sey3aSEjI2HODU4Ov0wV61T18R6JmY6FkyMScCWfZ34PMVctGQO166dz5Z9nQTH8q+87amhUSD6hsWwOZ5iqkqLaOu2FV1mahZMjIlTKKQ89VoXV6+aS2GBcP26+fSPjPFcy8lsNy1u4Zxb0wUTEWFRjcdSqphpWTAxJk47j57CHwjyljXzALh8RR0VJYU8vif/hrpO736fOpiAk1bFhrnMdNIWTERktYjsiPjqE5EvisgDEccOi8iOKZ7/HRHpFJFXJx3/iogci3iNm9J1DcZEs2VfJwUCV62cCzi7xN+0eh5P7DlBKJRfGxh73CSP0WqZRFpc6+Gof4jxPLs+kzlpCyaqul9VN6rqRuAiYBD4qaq+J+L4g8BDU7zE94C3TvHYP4VfQ1UfTXnjjZnGlv1dXLB4zhl/gK9fN5+u/hFePtKTxZbFrzsQY8+kpoLgeIjjfcOZaNY5Kd8+iEyWqWGua4AWVW0NHxARAd4N3B/tCar6NODPTPOMiU1n3zCvHOudGOIKe/OaeRQXCpvzbFVXuJbJjD2TieXBNgmfDpt3H2fDXz7Oq8d6s92UhGUqmNzO2UHjSuCEqr6ewOt9VkR2uUNhc6KdICKfEJFtIrKtq6srgW9hzNme2u/8LL159ZnBpLqsmMuW17F59/G8ytXlD4xQXVZEceH0fwosFX36PN/Szefuf5mBkTFaugay3ZyEpT2YiEgJcAvw40kP3cEUvZIZ/DuwHNgIdAD/EO0kVb1bVTep6qa5c+cm8G2MOduW/Z3UV5extqHqrMduWDef1u5BXjuRP38Q/DPsMQlr8JZRVCC2cTHFXj3Wy8e/v425lU76/153qXY+ykTP5EZgu6pO9P9FpAh4J/BAvC+mqidUdVxVQ8A9wCUpa6kx0wiOhXjm9ZO8ec1cnFHaM123dj4izpBFvvAHRmIKJkWFBSycU27Lg1Po0MkAH/7uVrzlxfzwE28A4NSgBZPpROuBXAvsU9Wj8b6YiDRE3H0H8OpU5xqTStsO+xkYGTtriCtsXnUZFyzy8fie/Akm3QNBaqIUxYpmUY2HNuuZpMSJvmE+8O0XCCl8/2OXsKjGQ0VJofVMpiIiFcB1nL1i66w5FBFpFJFHI+7fDzwPrBaRoyLyMfehu0TkFRHZBbwZ+IO0XYAxEbbs76SksIDLV9RNec4N6+p59VgfR3vy449uz2CQmorimM61vSap0Ts4yge/vZWeQJDvfeRils+tBMDnKcnrnsnZpdVSSFUDQG2U4x+OcqwduCni/h1TvOYHUthEY2L2q32dXLqshorSqX9trl9Xz9/87z4e332Cj16xNIOti5+qukkeY+uZLKmpoHdolN7BUbye2AKQOdNQcJyP3fsih04G+O5HLmbDQt/EY97yYnqHgllsXXJsB7wxMWjrHqSlKzDlEFfY0roKVs2vzIuhrv6RMUbHdcY9JmET9eCt6mJCRsdDfPoHL/FSWw//fPvGs3q4Pk9xXvdMLJgYE4Mtbor5yftLorlhXT1bD/kn8l7lqp5AbHtMwsLLg21FV/xCIeWPf7KLLfu7+Ovb1nPT+oazzvF5iicSb+YjCybGxOBX+zpZWldBU13FjOde31xPSOGXe3N7A2Osu9/DwhsXbd4kPqrKX/3PXn768jG+fP0q3nvp4qjnecvze87EgokxMxgMjvH8we4Zh7jCzltQzQJfec7XOAnvfo9laTBARWkRdZWltqIrTv/2VAvf+c0hPnJ5E59584opz/N5nDmTfNr0GsmCiTEzeO5AN8GxUExDXOCkbL+ueT7PvN7FYDB3y/n6B+MLJgCLa8ptziQOD750lL/bvJ93XLCAP39bc9T9SWG+8mJGx5XB4HgGW5g6FkyMmcGW/Z14Sgq5eGnUzD1RXb9uPiNjIX69P3dT+cRSy2SyJbUVHPEPpatJMft/j+7lM/dtz3YzZvT937bS3FDNXe/aQEHB1IEEnNVcQN7Om1gwMWYaqsqWfZ1csaKO0qLCmJ93SVMNczzFOb0b3h8IUlpUgKck9utaXOOhvXeIkbHsfnp+ruUkWw/ldh7YsfEQ+zr6eOPy2hlzn4EzzAXOPpR8ZMHEmGnsP9FPe+9wzENcYUWFBVyzdj5P7utkdDw3y/n6A0FqK0qmHXqZbEmtB1U42pPd3klb9yAnB0ZyulTy4e4AI2MhmhurYzrfW+70EE/l6V4TCybGTGPLPjdLcJzBBOD65vn0D4/x24PdqW5WSvgDwZiXBYdNrOjK4iT8qcEgfcNjqDppSXLV7vY+gJiDifVMjJnFtuzrpLmhmvnVZXE/96pVcykvLszZoa7uQDCu+RJwKi5CdpcHR37vXC7Wtaejj5LCgol0KTMJBxObMzFmlukdHOWltp64h7jCyooLuXrV3Jwt5+sPjMS8xyRsbmUp5cWFWd24GPm9209lfzHAVPa097GqvjKm+RIAX3iYy3omxswuT7/exXhIExriCrvhvPmc6Bth59FTKWxZavQERuMe5hIRFtd4aMvi8uAzeia9udkzUVX2tPfR3BDbEBdAWXEBJUUFNmdyLms/NcTn7n+Z1070Z7sp0xoMjnHrvz7LtsO5vQomV2zZ18kcTzEbF/lmPnkKb1k9n6KC3CvnOzI2zsDIWNw9E3CGurLZM2nrHqSuspSq0iI6cjSYdPWP0B0IxhVMRARfebHNmZyrXjvRz+/8+3P8fGc7D+84lu3mTGtvRz87j/byRI6n+cgF4yHlqde6uHrVXApn2B8wHa+nmDcsq825xI+n95jEljE40pIaJxV9tnZqt/kHWVxTTr23jI7e3Bzm2t3hTL6vjSOYQH4ne7RgkoSXWv387reeZyykzK8uZf/x3O6ZhOtL73FXmZip7Tp6Cn8gmNQQV9gN6+ZzsCvAgc7c+fk4HUziTyW/pNbDyFiIzv6RVDcrJm3+QZbUVtDgK8/ZYa7w79jaGFdyhXnLi22Y61zzyz0neO89L1BTUcJDn3ojFzfVsLcjd/5YRNPSeTqY5Gv+n0zZsq+TAoGrV81N+rWua64HyKmhrmR6JhOp6LMw1BUcC9HeO8SiGg8N1WW052ow6ehjUU051WXxBWtveQm9Q7mbgmc6FkwS8KNtR/j9/36J1fVV/OSTl7GoxsPahmqOnRqifzh3u6jhnkl3IEhXlj5V5otf7e/kwsVz8Hnin1OYrN5bxvmLfDyxJxeDSfzXt6TWyZzc2p35SfijPYOoOkNtDb6ynN24uDfOyfcwn6eY3kHrmcx6qsq/PXWAP/7JLt64vJb7Pv4GaiudT3ar51cB5PQkfEtXgDq3vXs6bKhrKp19w7x6rC8lQ1xhFy2ew/7j/TnTI0wmmCzwlVMgcCQLe03CK7kW13po8Jbl5MbFwMgYh7oDNDd4436urzx/a5pYMIlRKKR89Rd7uOux/dxyfiPf/tDFVEaUb11d7wSTfTk6bzIyNk6bf5C3rXeGXCyYTO0pNzljovtLommq8zA0Op61eYbJ/IEgBeL88YpXSVEBjb5yWrMYTJbUeKj3lgO5t3Fx3/F+VGPf+R7J5ylmMDie9dxnibBgEoPgWIgvPrCD7/7mMB+5vIl/fs9GSorO/K9bOKecytKinJ2Eb+seZDykXLB4DgvnlNsk/DSe3HeCBm8Za9wPCKnQ5A4NHTqZG+nbuwNB5nhKZsxkO5XFNdlZHtzWPUhpUQFzq0pp9DpZCXJtefDejvjSqETyusOqvXnYO7FgMoOBkTE+du+LPLKznT9+62r+4ubmqL+AIsKq+ZU52zMJz5csn1tJc0O19UymMBQc59evdXFd8/y4EiDOZKlbofFwjgSTngRSqURaUuvJ2jDX4hoPIkJ9OJjk2C74PR19eMuLJ4JdPMI9xXzca2LBZBrdAyO8957f8lxLN3e9awOfftOKaf/ArK6vzqlx8UgtXc4fsWVzK2hurObQyUBOF27Klqdf72J4NMQN6+pT+rqNvnJKCgs4lIVJ62i6E0jyGGlxTQXdgSADI5n9GXKWBTuryarKinNy42J453siH0byOT+XBZNpfPUXe9h/vJ//eP9FvHvTohnPX9tQRe/QaM6N4YKzLLjBW0ZFaRHNDdWo5u78TjZt3n0cb3kxlyytSenrFhYIi2rKc6ZnEk4/n6jwH/RMruhSVdr8gxNLk4Gc27g4HlL2He9LaIgL8js/lwWTafzft6/j/k+8gWub58d0fnhFVy7+kW7pGpjIXhr+Qbd5kzONjod4cm8n16yZF3Nyvngsravg8MncqJ/uT3KYK5yKPpPXc3IgyGBwnCWTgkkubVw8dDLA8GgooWXBEFFtMQ+XB1swmUZNRQkXLo69VOuaeucHKNcm4VWVlq4Ay+c64/YLfOVUlxXZvMkkLx7y0zs0yvUpHuIKa6qt4HB3IOsZhMdDyqnB5ILJinmVFBUIu9t7U9iy6UUuCw5r9Jbn1DDXngTTqIR5wzVNbJjr3Ob1FFNfXZZzwaSzf4SBkTGWz3N6JiJCc2O19Uwm2bz7OGXFBSnZ9R5NU10FI2OhrA+D9g6NEtLE9piElRUXsrq+ileOZTKYOENqi2sqJo7Ve8voyqGNi3va+yguFFbMi62GyWRVpUUUiAUTg7PfJNeGucJpVCKL9DQ3eNl3vI/xHKyzkQ2qyuN7TnDVyrmUx1ETPR65sqLLH3D2uiQTTADWL/DyyrHejC04aeseQsRZhh/W6HM2Lnb250bvZE9HHyvnVZ21dSBWBQXi5OeyOROzpr6Kls6BnKr7HbksOGxtQxXDoyEO58jqomzbdbSXjt7hlK/iitTkBpNsr+jyB5w/VEkHk4VeTg2OZqwefKs/QH11GWXFp4N9eONirgx17WlPfPI9zOcpsdVcxumZBMdDObM5DZxlwRUlhcyvPp3Uzybhz7R593EKC4Rr1qZu1/tkDdVllBQVzKqeCZCxoa4jk1ZyATTk0MbFzv5hTg6MJDz5Hub0TGwC/pwXnoTPpaGulq4Bls+rPGPd+8p5VRQXik3CuzbvPs6lS2tSkthxKgUFwpIaD4eyvKKr283LVZtAxuBIq+udn6FdRzMTTFq7B89YyQWng8nxHFgeHP5glnzPpNjmTCKJyGoR2RHx1SciXxSRByKOHRaRHVM8/zsi0ikir046XiMiT4jI6+6/sS+3yoDl8yooLBD2H8+dP9ItnQNnDHGBk19pxbwq65kABzoHaOkKpHWIK6ypriIr2XYj9bjBZE4CtUwilRaFJ+HTX5J4KOjkNVs8KZhUlRVTWVpE+6ns90ySXckV5rM5kzOp6n5V3aiqG4GLgEHgp6r6nojjDwIPTfES3wPeGuX4ncCTqroSeNK9nzNKiwpZVleRMyu6AiNjtPcOTywLjmRpVRzhKojXr4ttP1EyltZV0OofzOry4O5AkMrSIkqLkl9osH6Bj1eOpn8S/kjP2cuCwxpyZK/JnvY+Fs4pn9grkiifp8SGuaZxDdCiqq3hA+KMubwbuD/aE1T1aSBasfJbgXvd2/cCt6W2qcnLpRVd4bmbyT0TcLrjXf0jObMSJls27z7B+Qu9NHjLZz45SU21FRMFnrIl2Q2LkdYv8NI3PDaxByRd2tykkpN7JpA7u+D3diRWw2Sy6vJi+obH8m6lZaaCye2cHTSuBE6o6utxvtZ8Ve1wbx8Hon6cFJFPiMg2EdnW1dUV57dIzpr6Ko72DGU8b1E0Eyu5oqx7D//g53qFyHQ63jvMziOn0rZRcbKmuszvHJ8slcFkw8LMTMJPbFiMEkwavGVZn4AfDI5x8GQg6fkSOJ3sMZcL7UWT9mAiIiXALcCPJz10B1P0SmKlTt86avhW1btVdZOqbpo7Nz2b0KayOod2wrd0DlAgp3MpRQoHk3N53iQ8xHVDBoa44PRek2wuD05lMFk1v4qSwgJeSfMkfJt/kMrSoqjtbvCW0zUwktXl+PvDNUxS0DOZSPaYZ/MmmeiZ3AhsV9WJmqUiUgS8E3gggdc7ISIN7us0AJ0paWUKrZkolJX9P9IHugZYXOOJOj7u9RSzwFd+Ts+bbN59nGVzK1gxL3W1S6Yzv6qMsuLsLg9OZTApKSpgTUP6d8KHEzxGy8SbCxUXUzX5DvmbOTgTwSRaD+RaYJ+qHk3g9R4BPuTe/hDwcBJtS4tcKpTV0hmYNrXD2oZq9mQwv1Iu6R0c5bcH/RlZxRVWUCBOjq4sBRNVTTpj8GTnZWAnfGt34KxlwWENPrfiYhaHuva091FVVnTG7vxEeScyB+fXJHxMwURElotIqXv7TSLyeRHxxfC8CuA6zl6xddYciog0isijEffvB54HVovIURH5mPvQ14DrROR1nKD0tViuIZNypVDWeEg5dDIQdfI9LFzbZCiYf2VCk/XkvhOMhzSjwQScSfhsDXM5JWFDSdUymWzDAi/9w2Npq7wYCilHeoairuSC03tN2rMZTDoSr2EymS9Pkz3G2jN5EBgXkRXA3cAi4L6ZnqSqAVWtVdXeScc/rKrfmnSsXVVvirh/h6o2qGqxqi5U1W+7x7tV9RpVXamq16pqtBVfWZcLhbKO9gwSHA9NH0waqgkp7D+R/V5Upm3efZz51aVscHdyZ0pTXQVH/IOMZWGM3+/uMUnVMBc4PROAXWka6jrRP0xwLBR18h2YqLiYrY2L4yFlX0d/Sibf4fQE/GydMwmp6hjwDuAbqvpHQEP6mpX/1tQ7hbJO9I1krQ2nV3KdvcckbN05mlYlXJ73+ub6hOugJ2ppnYfRcc3KRrvTu99TF0xWzXcSG76apmAy3bJggGp342K2VnQd7g4wNDqeksl3iKxpMjuDyaiI3IEzR/EL91hyO3NmudU5MAnf0umW6q2bumeycE45VaVF7Ok4t+ZN0lWeNxZNtdlb0XV693vqgklJUQFr66vYdTQ9O+Fb3WXB0VYkhtV7y+jI0i74VKVRCSsqLKCqtIhTQ7NwzgT4CHAZ8NeqekhElgL/lb5m5b/TK7qyN3zU0jVAbUXJtH84RIS152Btk3B53kuXpbY8byzC2YOzkVYlHT0TcDII7z7Wl5ad/Uf8gxQWCI2+qSe3G7xldGRpNdeeDqeGycoUrgisLi+mdzb2TFR1j6p+XlXvd3NhVanq36a5bXnN5ynJeqGsyFK902luqGbf8f6823GbqLE0l+edybyqUjwlhVnJLJ2qjMGTrV/gpX9kLC0lDVq7B2n0lU37XjV4y+g4lZ05kz3tfaxIooZJNPmY7DHW1VxPiUi1iNQA24F7ROQf09u0/JfttCotXYFp50vCmhurGQyOZz0BYaZsTXN53pmICEuytDzYHxilpLCAytKilL7u+gXO4s507Ddp8w9OOV8SVp/FjYt7UpRGJZLPUzxr95l4VbUPZ6Ph91X1UpxluWYa2SyU5Q8E8QeCMfdMgHNm8+Lm3ccpLSrgqlV1WWvD0joPh9O0lHY6/sAIcyqKU7KENdLK+ZWUFKVnJ3wswaTRG664mNkFL139I3T1j6RsviTMV55/yR5jDSZF7m7zd3N6At7MIFwoKxufQA9Gqa44lZXzKykqkHNi3mSiPO+quXhKUvvpPB5NtdlZHuzsfk+ujkk0xYUFNDdUp7xn0j88ij8QPKPuezTh5cGZHura634AS3XPxDtbh7mArwKbcTL/vigiy4B4EzSec1ZncRI+WqneqZQWFbJiXuU50TPJRHneWDTVVTAW0oyVvA1L9e73SOsXeNndntpJ+CN+5/9nxp6JLzvle/ekKZiEa5pkc59avGKdgP+xqm5Q1U+59w+q6u+kt2n5b8W8SrdQVjaCSYCSogIWxJjeobnh3FjRFS7Pe20ay/PGIlsJH/2BYEqXBUdav9DLwMhYSq+pze+81nTLgiGiZ5LhjYt72sYZX4EAACAASURBVPtY4CvH60ntTgmfp5ixkBLIo8wUsU7ALxSRn7qVDztF5EERWZjuxuW7cKGsbOw1aekcYFmdU/UxFs2N1XT2j3ByIHubLDPh8T0n0l6eNxbhvSaZHgLtTnPPBEjpvEk49fzk2u+TVZUWUVFSmJWeSSqSO07my8P8XLEOc30XJ8Fio/v1c/eYmUG2VnTFuiw47HRtk9nbO2npGuBA5wDXN2cm3fx06ipLqCwtymgwGR0P0T88lvJlwWEr51VSWlSQ0nmT1u5BfJ7iGasXiggNvvKMJnscCo5zsGsg5ZPvwERPJ592wccaTOaq6ndVdcz9+h6Q2SIheSobhbJGxsZp8w9GLdU7lbXnQG2TzbvD5XmzO18Czh+/pjoPhzK4oisdu98jFRUW0NxYnfKeyUzzJWEN3rKMJnvcf6KfUIpqmEwWDp75NAkfazDpFpH3i0ih+/V+oDudDZstslEoq7V7kJBGr644lTkVJTR6y2b1JPzm3SfYsNA77U7qTMp0Kvp07X6PtGGBl93tvSnbABtvMMlkssfwB691aeiZ5GPm4FiDyUdxlgUfBzqAdwEfTlObZpVwWpVMBpOWzthXckVqnsVpVY74B9l55FTWV3FFWlpX4WR2HsvM8uB0ZAyebP1CH4HgOIdODiT9WmPjIY71DMUcTOq95XT2J75xcXh0nOHR2Ce893T0UlWamhomk52eM5llwURVW1X1FlWdq6rzVPU2wFZzxWCBr5yKkkL2Z3ASPrwseFkcw1zgdNdbugbi+oXKF9/9zWGKCoR3XLAg202ZsKS2gpA6pQIyISPBZEHqasJ39A4zFtIZV3KFNSS5cfHOB3dx2d88yZN7T8x8Mk7PZG1jamqYTHa62uLsm4CP5kspa8UsVlAgGZ+Eb+kKsMBXHvemvOZGt7ZJHG3tHRrlzgd38VoO10PpHRzlhy+28fbzG3NmiAucXfBAWvJZRZOJYLJ8bgXlxYXsSsG8SawrucIakqhroqo8/fpJ+obH+Ni92/jKI7un/VA1HlL2He9Py3wJQFlxIaVFBXmV7DGZYJLZIhB5bHW9k0gxUxuQWroG4u6VADQ3OJ8qY503UVX++Cc7+eGLR/jzn72asxus7tvaxmBwnN+7cmm2m3KGiVT0JzPTM+kOBBGBOWlcFh2ehE9FbZPWGeqYTNbgdT4oJFIn5nD3IP5AkL+4uZmPXr6U7z13mNu++RsOdEb/kNTaHWAwOJ6WlVxhPk/x7BvmmkJu/uXIQZkslKWqtHTGtyw4LFy7PtZ5k+/85jCbd59g05I5vHDIz1OvdcX9PdMtOBbiu785xBUr6ljXmNmKijOpqSihqixzy4N7AkF85cUx7z1K1PoFXl491pf0JHybf5DiQpkIEjNp8IV7JvEHk5daewB4w7Ja/uLtzXz3wxfT1T/Czd94lh9ubTvrg1K6dr5H8pWXzJ5hLhHpF5G+KF/9OPtNTAwyWSjreN8wgeB4XCu5wgoKhLUNVTH1TF5u6+FvHt3Ldc3z+cHHL2VxjYe7HtuflnoWyXhkZzud/SN8/Kpl2W7KWUSEpXUVGR3mStey4EjrF3gZGh2fyA+XqDZ/gIVzPDEHv/DGxfYEhrm2t/VQVVrESvf35s1r5vG/X7iSTUtquPOhV/jsfS+fsbJqT3sfRQXCyvnx/57FyjubeiaqWqWq1VG+qlQ1e1ny8kwmV3SFqyvGs8ckUnNDNXs7ps+vdGowyGfve5l6bxl//67zKS0q5A+vX8Xejj4e2dme0PdNB1XlnqcPsqa+iqtWZi9D8HSaaisyVtekOzCS1mXBYRsWujXhk5w3iWdZMDjBud5bllDPZHtrDxsX+84o4Tyvuozvf/QS7rxxDZt3H+emf3mGbYf9gNMzWTGvktKiwri/V6x85fmV7DHzlYHOQT5PCfOrSzMTTNxPgysSGOaC07VNwpOfk4VCyh/+aCed/cN8870XTuzUffuGRpobqvmHJ/ZnbKnrTH79Whf7T/Tz8SuXpWXFTSo01VXQfmqIkbH0r6DrCYymdfI9bNncSjwlhUmv6Grrji+YgJPwMd6UKv3Do+w/0c9FS+ac9VhBgfDJq5fzk0+9kcIC4d3/8Txff/J19rSnvobJZN7yWdQzMamzxp2ET7eWrgGqSouYW5VYmvGZJuHveeYgT+7r5M9uWsv5i3wTxwsKhD+5cQ1H/EPc90JrQt871e555iDzq0t5+/m5OyK7tM5DSJ19MOnWHQhmJJgUFgjrGpNLR39qMEjf8FjMy4LD6qvL4k72uOPIKVThwsVnB5OwjYt8/M/nr+Dt5zfyj0+8RmcaaphM5hTImiVzJiZ11tRXcSADhbJaugZYNq8y4U/iK+c7mY6jTcJvO+znrs37ufG8ej78xqazHr9qZR2XLavlG786kNH0MdG8eqyX3xzo5iOXL01pOdVUy9SKrlBI6RnMTDABOG+Blz3tfQnXa4l3WXBYg7cs7o2L21tPIQIbF/umPa+qrJh/fs9G/uF3z2fFvEretDq9GaV8nhKGR0N5s+8rd3/LZplMFcpq6QwkPF8Czvr2FXPPrm3iDzjzJAvnlPO379oQNViJOL2T7kCQ/3zmYMJtSIX/fOYgFSWF3HHJ4qy2YybhVPTp/rnoHx5jPKRpKYwVzYaFziR8S1di1xVeFhxvz6TBVx73xsXtbT2smldFddnMaeRFhN+5aCG//NLVrJhXFVfb4hXOz9WXJ/MmFkwyJBOFsgZGxjjeN5zQsuBIk9OqhELKHzywA38gyDffe+G0v3QbF/m48bx67nn6YNbS2befGuLnuzq4/ZLFM2abzTafpwSfpzjtdU26A857UVORmf+PZHfCT/RM5sQ5zBXnxsVQSNne1sOFUeZLsu30LngLJiZCJgplxVOqdzrNDdUc7xum2w0G//7rFn79Whd//vZmzlsw816NL9+wmuGxEP/6qwNJtSNR3/3NIQA+ekVubVKcSiYSPp7e/Z6ZnsnSukoqSgp55eiphJ7f1j1IXWUpFaXxLRpt9MZXcbGla4D+4TEunGGIKxvyLT+XBZMMKS0qZGldRVp7JhMrueYlPswFTEws7u3o57cHu/mHx/fz9vMbef+lsQ0ZLZ9bybs3LeQHL7RmZGI5Ut/wKPdvPcLNGxpYkEOpU6bTVOuZGNZJF38GMgZHcibhvUn1TBbXxP/+na4FH1swCW9WzOmeSZ4UyLJgkkFr6qvYfyJ9GxdbOgMUFgiLa5ILJuHaJk+/3sXn73+ZptoK/uad6+Oa1P/CNasoEOEfn3gtqbbE64db2xgYGePjV+beJsWpNNVV0N47lNaJVn+aa5lEs36hlz0diU3Ct/kHWVIb/89xdVkRnjgqLm5v68HnKWZZXXK/M+kQHqK1YS5zljX1VRzxp69QVkvXAEtqPEmvXqqpKKG+uoy7nz5I79Ao33zfhVTGOdxQ7y3jI5cv5Wc7jmWsemNwLMR3nj3MG5fXxjQclyuW1lWgypR7e1IhE7VMJlu/wMvwaIgDce6ED46FaO8dinslF7gVF72xLw9+qbWHCxfPycl9SBM1TWyYy0yW7kJZToLH1KR3CA91/eUt6xKucf2pq5dTVVrEXY/tS0mbZvKLXe0c7xvOydQp0zm9PDh98yb+QBBPSSFlxenbsT3Z+gR3wh/tGUQ19gSPkzV4Y9u4eGowSEtXIOpmxVxQWVpEYYHkzV6TtAUTEVktIjsivvpE5Isi8kDEscMismOK579VRPaLyAERuTPi+PdE5FDEa2xM1zWkWjrTqoyNhzh8cpDlSc6XhP3elUv5s5vW8J6LFyX8Gl5PMZ9+8wq27O/ihYPpLcypqtz99EFWza/kTavyq6J0UwaWB/dkaMNipKW1FVSWFsWdQTjcQ4t3WXBYQ4wpVV4+4iwOuCAHJ9/B6WXl0y74tAUTVd2vqhtVdSNwETAI/FRV3xNx/EHgocnPFZFC4JvAjUAzcIeINEec8kfh11DVqMEoF6WzUNbRniGC46GkV3KFvXF5HZ+4annS3f8Pv7GJ+uoyvvbYvrSmqH/2wEn2Hc/t1ClT8ZYXU1NRktaEj5na/R6pwN0JH2/PJBxMEu+ZlNHZPzzjXM321h4KC4TzF+ZmMIH8ys+VqWGua4AWVZ3IsyHOb/y7gfujnH8JcEBVD6pqEPghcGtGWppGBQXCqjQVyjq9kit9WUwTUVZcyBevXcnLbad4fE9sFewScffTB5lXVcotG3M3dcp0mmo9aR/mynQwAWfeZG9HX1w70tu6ByktKmBegimB6r3lhGLYuLi9rYc19VVxLz/OJK/Hgslkt3N20LgSOKGqr0c5fwFwJOL+UfdY2F+LyC4R+ScRifoTJyKfEJFtIrKtqyt36mycv9DHttYevvXrlpSmaw8Hk+V1uRVMAN510UKWz63g7zbvTzi9xnT2dvTxzOsn+fDlTWnN4ppOTXUVHE5jSpWsBZOFXkbGQrx+IvZJ+HC24ER7mOG6JtNNwo+HlB1tp3J2viTMZ8Ncp4lICXAL8ONJD91B9F7JTP4UWANcDNQAfxLtJFW9W1U3qeqmuXNzZwz9D69fxVvX1fO1/93HR+99cWLJZrJaOgPUVZZOZPHNJUWFBfzRDas50DnAQ9uPpfz173nmIJ6SQt53yZKUv3amLK2t4HjfMEPB9CwP9geC1KSxwuJUwjvh45k3cZYFJzbEBafL9043Cb//eD+B4Pi0yR1zgc+TPwWyMtEzuRHYrqoTYxwiUgS8E3hgiuccAyJnfhe6x1DVDnWMAN/FGRLLG1Vlxfzrey/g/7vtPJ470M1N//IML7o1EpLR0jWQVE6udLthXT0bF/n4xpbXUzp30tE7xCM72nnPxYtyMpDGamISPg3zJkPBcYZGx6mpzHwwaaqtoKq0iF3HYtsJr6q0+QcTWhYcFq7MON0k/Ett7mbFHA8mNgF/pmg9kGuBfap6dIrnvAisFJGlbs/mduARABFpcP8V4Dbg1bS0Oo1EhA+8YQkPffqNlBUXcPvdv+XfnjqQ1LBXS9dAQtUVM0VE+OBlSzjiH5pYRZMK33++FQU+enl+pE6ZSjoTPh7tcYbPMrnHJKygQDhvgZcn93ZyoHPmoa6TA0EGg+MsSSKYhDcuTlcL/uXWHuoqS1mUwC77TPJ5iukfHkvL8HCqpTWYiEgFcB1nr9g6aw5FRBpF5FEAVR0DPgtsBvYCP1LV3e6pPxCRV4BXgDrgr9J3Bel13gIvP//cFdx4Xj13Pbafj3zvxYl8WPHoHhihZ3A0ZSu50uXa5vmUFBbwi50dKXm98ZDy0PajvHn1vKQ+yeaC8LBOqhM+7m7v5YPf2YqnpDBr8wNfun4VI2MhbvnXZ3l4x/TDnBMruZIY5pqouNg39ZzJ9rYeLlzsy/mVf75w5uDh7JZ0iEVag4mqBlS1VlV7Jx3/sKp+a9KxdlW9KeL+o6q6SlWXq+pfRxx/i6quV9XzVPX9qppcoeksqyor5ht3XMBf3XYezx/s5m1ff5ath+Ib9gqn+c7lYS6A6rJirl49l0df6UjJ4oMXDnVzom+E2y7IzxVckarKiqmrLKE1hZPwT+w5we9+63kAfvzJy9KeMn0qFzfV8D+fv4J1jdV84Yc7+LOfvjJl6pg2v/OznGxKoEZv+ZQ9k5MDIxzuHsz5yXdgYug2H/Jz2Q74HCAivP8NS3joU86w1x33/JZvbol92KslRdmCM+HmDQ0c7xtmm5tgLxmP7GinoqSQa9bMT0HLsq+ptiIlPRNV5Z6nD/KJ/9rGynmVPPyZy1nXmN30Mg3ecu77+Bv4/auXcd8Lbbzz356LOqTX1u30JhbOSW74abpa8C+3OcOsuZjccbKJzMF5sDw4dxdYn4PCw15/+tAr/N3m/fz2YDdXrKhjMDjO8Og4g8HxiNtjE7ePnRqitKggL7LkXrt2PmXFBfxiVzuXLK1J+HVGxsZ59JUObjivnvKS/FwOPFlTXQVPv5bcMvbgWIg//9mrPLDtCDetr+cffndjzvz/FBcW8Kc3ruWSphq+9KOd3PyNZ7nrXRu4aX3DxDmt/gD11WVJp31pjNi4WFR45mfml1p7KC6UiZVmuSzcM8mHvSYWTHJMeNjrsuW1fPXne3jm9ZMAlBUX4Ckpory4kPKSwol/fZ4SGn3lXNxUQ0FBbo//AlSUFvGWNfN49JXj/N+3r6MwwTY/tb+LvuExbt24YOaT88TSugp+8tJRAiNjCW2kOzUY5JP//RK/Pejnc29ZwR9cuyonfyauWTufR79wJZ+9bzuf/sF2PnTZEv7sbWspLSrkiH8wqfmSsMiNi42TPmRtb+uhudGb0TxliQrPmeRDskcLJjlIRHjfpUv4nQsXElKlrKgwJ/8oJOpt6xt59JXjvHComzcur0voNR7ecYy6yhIuX16b4tZlTzjh4+HuQNzDUge7BvjYvds41jPEP73nfN5xwcJ0NDFlFvjKeeATl/G3j+3j288e4uUjp/jmey+ktXuQq1KQWy1yr0lkMBkdD7Hr6KmcL+cc5vOEC2TZnIlJQllxIZ6SolkVSADesmYenpJCfrErsVVd/cOj/HJvJzdvaDxrCCOfNdU5n8jj3Qn/3IGTvOPfnqNvaJT7Pn5pzgeSsJKiAv785mb+4wMXcehkgLd9/Rk6+0eSWhYcNtUu+L0dfQyPhvJi8h2cZc6QH3Mms+c30eSN8pJCrlk7n8dePZ7Q+vnHXj1OcCzErXmah2sqkT2TWN2/tY0Pfmcr86pK+dlnLmdTU+LzUNlyw7p6/udzV04Uw2pKQaGqhuroGxe3t+bHZsWwosICqsqK8mLjog1zmay4eUMDP9/ZznMt3XEPazyys50ltR42LsrdbK+JqCgtYl5VaUwJH/e09/EfT7fw8I52rl41l2+89wKqy/I3A8DiWg8/+dRlbNnXxbVr5yX9etXl0SsuvtR2igZv2VnzKLnMlyfJHi2YmKy4etVcKkuL+MWu9riCSWf/ML85cJLPvnlFzm84S4ST8DF6MAmFlKde6+Q/nznEcy3dlBcX8uk3LedL162aFcN9pUWFvPW8+pS8Vnjj4uRhru1uZcV84isvyYs5EwsmJivKigu5rnk+m3ef4K9uC8VcavgXOzsIKdwyi1ZxRVpaW8GT+85M1T8UHOehl4/y7WcPcbDLWTp7541ruOPixXmdjyzdnPK9p3smJ/qGOXZqiI9ekV+pd7zlxXkxZ2LBxGTNzRsa+OnLx/jNgZO8eU1sQxsP7zjGeQuqc65uS6o01VVwciBI//AoQ8Fxvv98Kz94oZWewVHWL/DyL7dv5Kb1DRTPgp5IujV4y3nWXVoPkfMl+TU86vUU034qtpr22WTBxGTNlSvnUl1WxM93tccUTA6dDLDzaC//56a1GWhddjS5eyw+c9/LPN9ykrGQct3a+fzelcu4uGnOrBzaS5eGSRsXX2rtoaSoIOvZAOKVL9UWLZiYrCkpKuCGdfU89upxhkfHZ9xE9vCOY4jA28+fXau4Iq2c7+TPevGQn/despiPXL40JaubzkUN7sbFroERGrzlbG/rYcMCb8xDqrnC53GGuVQ1pz9MWDAxWXXz+Y38+KWjPP1aF9evm3ryVVV5ZEc7b1haS727IW02WjGvkp988jJWzquy+ZAkhTcutp8apqaihFeP9fHhy5uy26gE+MpLGA8pAyNjVOXwir38CtFm1nnj8lrmeIpn3MD4yrFeDp4MzLq9JdFsaqqxQJIC4Q8dx3uHefVYH8HxUN6t5ILIzMG5PdRlwcRkVXFhAW89r55f7j0xZVpygId3tFNSWMCN5zVMeY4xkRrdiosdvUO8HK6suCS/Jt8hIj9Xjs+bWDAxWXfzhkYGg+Ns2dcZ9fHxkPLzne28afVc+8RuYlZd7iRG7egd5qXWHhbVlDOvKv+GSE/n57JgYsy0Ll1aQ11lyZRDXb892E1n/wi3XTA795aY9BARGnzOxkWnsmL+DXGBMwEPcGootzcuWjAxWVfkDl89ue8EgZGzy5M+vOMYlW7qemPi0eAtY3vrKU70jeRNcsfJvOU2Z2JMzN62oYHh0RBPThrqGh4d539fOc5bz6vPi/oTJrfUV5dzvM/ZBZ+vPROvzZkYE7uLm2qYV1XKL3a2n3H8qf2d9I+MnROruEzqNbqp6MuLC1lTX5Xl1iSmrLiQsuICCybGxKKwQLhpfQNPvdZF//DpX5qfvdxOXWVpwkW0zLktvDz4/EXevE6GmQ/JHvP3f9fMOm8/v4HgWIhf7nUSHfYOjfKr/Z28/fyGhMv7mnNbeHlwvg5xhfk8xXHPmRztGeTWb/6GbYf9aWrVmSyYmJxxwaI5NHrL+MVOZ1XXZrcI1m2zNEOwSb+V8yspKSzgTavze/FGIpmDtx7ys/PIKTwlmUl0YsHE5IwCd6jr6de76B0c5eGdx2iq9bBhYX4l5jO5Y+EcD7u/egOXLM2/CpSRfJ5ieuPsmbx42E9VWRGrMzRXZMHE5JSbz29kdFz57xdaea6lm1s3Lsjp5HYm982GdP2+8pK495lsPeRn05I5GRsizv//ZTOrnL/Qy6Kacv75l6+hiq3iMob450xODozQ0hXg4gz2yCyYmJwiIrxtvdM72bDQy7K5s7MIljHxqC4vZmQsNG3+ukjhSfdLLZiYc9ktbr0Sm3g3xuGLM3Pw1kM9lBYVsH5B5hJbWj0Tk3OaG6v5+WevYG1Dfm4yMybVfOVOssfeodGY6vm8eNjPxkW+jBYCS9t3EpHVIrIj4qtPRL4oIg9EHDssIjumeP5bRWS/iBwQkTsjji8VkRfc4w+ISEm6rsFkz/qF+b3JzJhUOt0zmXkSfmBkjN3tvRlfwZa231ZV3a+qG1V1I3ARMAj8VFXfE3H8QeChyc8VkULgm8CNQDNwh4g0uw//LfBPqroC6AE+lq5rMMaYXDCR7DGGvSbbW3sIqZOiKJMy9dHvGqBFVVvDB8RZ7/lu4P4o518CHFDVg6oaBH4I3Oo+5y3AT9zz7gVuS2vLjTEmy8I9k1j2mrx42E9hgXBhhrMkZyqY3M7ZQeNK4ISqvh7l/AXAkYj7R91jtcApVR2bdPwsIvIJEdkmItu6urqSarwxxmTTRIGsGPaavHDIz7rGaipLMzslnvZg4s5p3AL8eNJDdxC9V5ISqnq3qm5S1U1z585N17cxxpi0qygppKhAZlzNNTI2zo4jpzI+xAWZWc11I7BdVU+ED4hIEfBOnLmUaI4BiyLuL3SPdQM+ESlyeyfh48YYM2uJiLNxcYY5k1eO9hIcC2UlmGRimCtaD+RaYJ+qHp3iOS8CK92VWyU4w2SPqKoCW4B3ued9CHg4DW02xpicUl0+c36ure5mxYubMp8lOa3BREQqgOs4e8XWWXMoItIoIo8CuL2OzwKbgb3Aj1R1t3vqnwBfEpEDOHMo307fFRhjTG7wlRfPOGfy4iE/K+ZVUltZmqFWnZbWYS5VDeD8wZ98/MNRjrUDN0XcfxR4NMp5B3FWexljzDnD5ymhs394ysfHQ8q21h5u3pCdfHa2K8wYY/KAr3z6ZI/7jvfRPzzGJUuzUwjMgokxxuQB7ww1TV48FJ4vyU7tFgsmxhiTB3zlJfSPjDE6Hor6+IuHe2j0lrFwjifDLXNYMDHGmDwQ3gXfF2V5sKqy9bA/o/VLJrNgYowxeWAi2WOUYNLaPUhX/0hWyxNbMDHGmDwwkewxyrxJeH/JJVmaLwELJsYYkxfCwaQ3yl6TrYf8zPEUs2Je9iqTWjAxxpg8MJHsMUrP5MXDfjY11eAkVs8OCybGGJMHfBM9kzODSWffMK3dg1kd4gILJsYYkxeqp5gzmZgvyeLkO1gwMcaYvFBYIFSXFZ3VM3nxkB9PSSHrGquz1DKHBRNjjMkTPk/JWXXgtx7u4cLFcygqzO6fcwsmxhiTJybXNOkdGmXf8b6spVCJZMHEGGPyhHdSsseXWv2owsVZSu4YyYKJMcbkCZ+n5Iw5k62HeiguFC5YZMHEGGNMjLzlRWfMmbx42M/6BV7KSwqz2CqHBRNjjMkTvnKnZxIKKcOj4+w6eiqryR0jpbXSojHGmNTxeYoJKQwEx9jT3sfouGZ9s2KY9UyMMSZPTOTnGhxl6yE/IrBpiQUTY4wxcYjMz/XiYT+r51fhdVPTZ5sFE2OMyRPhmiYnAyNsb+3JegqVSBZMjDEmT4STPT7f0k0gOJ4TmxXDLJgYY0yeCA9pPbHnBJD95I6RLJgYY0yeCE/AHzoZYHGNh/nVZVlu0WkWTIwxJk+UFhVSXuxsUMylIS6wYGKMMXklPAl/aQ4NcYEFE2OMySvhoa5c2fkeZsHEGGPyiM9TTF1lKU21nmw35QyWTsUYY/LI712xjEBwDBHJdlPOYMHEGGPyyLXN87PdhKjSNswlIqtFZEfEV5+IfNF97HMisk9EdovIXVM8/wsi8qp7zhcjjn9FRI5FvO5N6boGY4wxsUlbz0RV9wMbAUSkEDgG/FRE3gzcCpyvqiMiMm/yc0XkPODjwCVAEHhMRH6hqgfcU/5JVf8+XW03xhgTn0xNwF8DtKhqK/Ap4GuqOgKgqp1Rzl8LvKCqg6o6BvwaeGeG2mqMMSZOmQomtwP3u7dXAVeKyAsi8msRuTjK+a+659SKiAe4CVgU8fhnRWSXiHxHRKLWqxSRT4jINhHZ1tXVlcprMcYYM0nag4mIlAC3AD92DxUBNcAbgD8CfiSTliWo6l7gb4HHgceAHcC4+/C/A8txhtA6gH+I9n1V9W5V3aSqm+bOnZvSazLGGHOmTPRMbgS2q+oJ9/5R4CF1bAVCQN3kJ6nqt1X1IlW9CugBXnOPn1DVcVUNAffgzKsYY4zJokwEkzs4PcQF8DPgzQAisgooAU5OflJ4Yl5EFuPMl9zn3m+IOO0dOENixhhjsiit+0xEpAK4Dvj9iMPfAb4jIq/irNT6kKqqiDQC/6mq4aW+D4pILTAKfEZVNDlB9AAABgxJREFUT7nH7xKRjYAChye9tjHGmCwQVc12G9JORLqA1gSfXkeUnlOem23XNNuuB2bfNc2264HZd03RrmeJqsY06XxOBJNkiMg2Vd2U7Xak0my7ptl2PTD7rmm2XQ/MvmtK9nos0aMxxpikWTAxxhiTNAsmM7s72w1Ig9l2TbPtemD2XdNsux6YfdeU1PXYnIkxxpikWc/EGGNM0iyYGGOMSZoFk2mIyFtFZL+IHBCRO7PdnkSIyGERecWt/bLNPVYjIk+IyOvuv1GTZeYKN6Fnp7vRNXws6jWI4+vue7ZLRC7MXsujm+J6pqzTIyJ/6l7PfhG5ITutnpqILBKRLSKyx60/9AX3eD6/R1NdU16+TyJSJiJbRWSnez1/6R5f6ibdPSAiD7i5FBGRUvf+Affxphm/iaraV5QvoBBoAZbhpHzZCTRnu10JXMdhoG7SsbuAO93bdwJ/m+12znANVwEXAq/OdA04Gab/FxCcZKIvZLv9MV7PV4AvRzm32f3ZKwWWuj+Thdm+hkltbAAudG9X4eTRa87z92iqa8rL98n9v650bxcDL7j/9z8CbnePfwv4lHv708C33Nu3Aw/M9D2sZzK1S4ADqnpQVYPAD3GKes0GtwL3urfvBW7LYltmpKpPA/5Jh6e6hluB76vjt4BvUj63rJvieqZyK/BDVR1R1UPAAXIsuamqdqjqdvd2P7AXWEB+v0dTXdNUcvp9cv+vB9y7xe6XAm8BfuIen/wehd+7nwDXTM7uPpkFk6ktAI5E3D/K9D9MuUqBx0XkJRH5hHtsvqp2uLePA7lZVHp6U11DPr9v0er05NX1uMMhF+B88p0V79Gka4I8fZ9EpFBEdgCdwBM4vadT6hQghDPbPHE97uO9QO10r2/BZPa7QlUvxCkF8BkRuSryQXX6sXm9Pnw2XAMx1unJZSJSCTwIfFFV+yIfy9f3KMo15e37pE7pjo3AQpxe05pUvr4Fk6kd48zqjgvdY3lFVY+5/3YCP8X5IToRHlZw/41WOjnXTXUNefm+6dR1evLiekSkGOeP7g9U9SH3cF6/R9GuKd/fJwB1MrBvAS7DGWIMZ4+PbPPE9biPe4Hu6V7XgsnUXgRWuqsdSnAmoR7JcpviIiIVIlIVvg1cj1P/5RHgQ+5pHwIezk4LkzLVNTwCfNBdMfQGoDdiqCVnydR1eh4BbndX1ywFVgJbM92+6bhj6d8G9qrqP0Y8lLfv0VTXlK/vk4jMFRGfe7scpzTIXpyg8i73tMnvUfi9exfwK7d3ObVsrzLI5S+cVSev4Ywt/p9styeB9i/DWWGyE9gdvgacsc8ngdeBXwI12W7rDNdxP86QwijOuO7HproGnFUr33Tfs1eATdluf4zX819ue3e5v8gNEef/H/d69gM3Zrv9Ua7nCpwhrF04JbZ3uL87+fweTXVNefk+ARuAl912vwr8hXt8GU7QO4BTWr3UPV7m3j/gPr5spu9h6VSMMcYkzYa5jDHGJM2CiTHGmKRZMDHGGJM0CybGGGOSZsHEGGNM0iyYGJMCIjIekUl2h6Qwy7SINEVmGDYmFxXNfIoxJgZD6qSqMOacZD0TY9JInHoyd4lTU2ariKxwjzeJyK/chIFPishi9/h8EfmpW3dip4i80X2pQhG5x61F8bi7i9mYnGHBxJjUKJ80zPWeiMd6VXU98K/AP7vHvgHcq6obgB8AX3ePfx34taqej1PzZLd7fCXwTVVdB5wCfifN12NMXGwHvDEpICIDqloZ5fhh4C2qetBNHHhcVWtF5CROKo5R93iHqtaJSBewUFVHIl6jCXhCVVe69/8EKFbVv0r/lRkTG+uZGJN+OsXteIxE3B7H5jtNjrFgYkz6vSfi3+fd28/hZKIGeB/wjHv7SeBTMFHMyJupRhqTDPt0Y0xqlLtV7MIeU9Xw8uA5IrILp3dxh3vsc8B3ReSPgC7gI+7xLwB3i8jHcHogn8LJMGxMTrM5E2PSyJ0z2aSqJ7PdFmPSyYa5jDHGJM16JsYYY5JmPRNjjDFJs2BijDEmaRZMjDHGJM2CiTHGmKRZMDHGGJO0/x/2uYTG9B2PwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Valid Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "plt.plot([i*10 for i in range(int(num_epochs/val_test_frequency))], val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
